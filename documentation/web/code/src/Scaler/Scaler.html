<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>src.Scaler.Scaler API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<link rel="icon" href="https://s3-eu-west-1.amazonaws.com/jonatan.enes.udc/serverless_containers_website/icon_serverless.png">
<style>
.footer_image {
max-width: 25%;
float: left;
padding: 1%;
}
</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>src.Scaler.Scaler</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#!/usr/bin/python
# -*- coding: utf-8 -*-
#
# Copyright (c) 2022 Universidade da Coruña
# Authors:
#     - Jonatan Enes [main](jonatan.enes@udc.es)
#     - Roberto R. Expósito
#     - Juan Touriño
#
# This file is part of the ServerlessContainers framework, from
# now on referred to as ServerlessContainers.
#
# ServerlessContainers is free software: you can redistribute it
# and/or modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation, either version 3
# of the License, or (at your option) any later version.
#
# ServerlessContainers is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with ServerlessContainers. If not, see &lt;http://www.gnu.org/licenses/&gt;.


from __future__ import print_function

import json
import time
from threading import Thread

import requests
import traceback
import logging

from requests import HTTPError

import src.StateDatabase.couchdb as couchDB
import src.StateDatabase.opentsdb as bdwatchdog
from src.Guardian.Guardian import Guardian
from src.Snapshoters.StructuresSnapshoter import get_container_resources_dict

from src.MyUtils.MyUtils import MyConfig, log_error, get_service, beat, log_info, log_warning, \
    get_structures, update_structure, generate_request_name, structure_is_application, structure_is_container
from src.StateDatabase import couchdb

CONFIG_DEFAULT_VALUES = {&#34;POLLING_FREQUENCY&#34;: 5, &#34;REQUEST_TIMEOUT&#34;: 60, &#34;self.debug&#34;: True, &#34;CHECK_CORE_MAP&#34;: True, &#34;ACTIVE&#34;: True}
SERVICE_NAME = &#34;scaler&#34;

BDWATCHDOG_CONTAINER_METRICS = {&#34;cpu&#34;: [&#39;proc.cpu.user&#39;, &#39;proc.cpu.kernel&#39;],
                                &#34;mem&#34;: [&#39;proc.mem.resident&#39;],
                                &#34;disk&#34;: [&#39;proc.disk.writes.mb&#39;, &#39;proc.disk.reads.mb&#39;],
                                &#34;net&#34;: [&#39;proc.net.tcp.in.mb&#39;, &#39;proc.net.tcp.out.mb&#39;]}
RESCALER_CONTAINER_METRICS = {&#39;cpu&#39;: [&#39;proc.cpu.user&#39;, &#39;proc.cpu.kernel&#39;], &#39;mem&#39;: [&#39;proc.mem.resident&#39;],
                              &#39;disk&#39;: [&#39;proc.disk.writes.mb&#39;, &#39;proc.disk.reads.mb&#39;],
                              &#39;net&#39;: [&#39;proc.net.tcp.in.mb&#39;, &#39;proc.net.tcp.out.mb&#39;]}

APP_SCALING_SPLIT_AMOUNT = 5


def set_container_resources(rescaler_http_session, container, resources, debug):
    rescaler_ip = container[&#34;host_rescaler_ip&#34;]
    rescaler_port = container[&#34;host_rescaler_port&#34;]
    container_name = container[&#34;name&#34;]
    r = rescaler_http_session.put(
        &#34;http://{0}:{1}/container/{2}&#34;.format(rescaler_ip, rescaler_port, container_name),
        data=json.dumps(resources),
        headers={&#39;Content-Type&#39;: &#39;application/json&#39;, &#39;Accept&#39;: &#39;application/json&#39;})
    if r.status_code == 201:
        return dict(r.json())
    else:
        log_error(str(json.dumps(r.json())), debug)
        r.raise_for_status()


class Scaler:
    &#34;&#34;&#34;
    Scaler class that implements the logic for this microservice.
    &#34;&#34;&#34;

    def __init__(self):
        self.couchdb_handler = couchdb.CouchDBServer()
        self.db_handler = couchDB.CouchDBServer()
        self.rescaler_http_session = requests.Session()
        self.bdwatchdog_handler = bdwatchdog.OpenTSDBServer()
        self.host_info_cache = dict()
        self.container_info_cache = dict()
        self.apply_request_by_resource = {&#34;cpu&#34;: self.apply_cpu_request, &#34;mem&#34;: self.apply_mem_request, &#34;disk&#34;: self.apply_disk_request, &#34;net&#34;: self.apply_net_request}

    #### CHECKS ####
    def fix_container_cpu_mapping(self, container, cpu_used_cores, cpu_used_shares):

        resource_dict = {&#34;cpu&#34;: {}}
        resource_dict[&#34;cpu&#34;][&#34;cpu_num&#34;] = &#34;,&#34;.join(cpu_used_cores)
        resource_dict[&#34;cpu&#34;][&#34;cpu_allowance_limit&#34;] = int(cpu_used_shares)
        try:
            # TODO FIX this error should be further diagnosed, in case it affects other modules who use this call too
            set_container_resources(self.rescaler_http_session, container, resource_dict, self.debug)
            return True
        except (Exception, RuntimeError, ValueError, requests.HTTPError) as e:
            log_error(&#34;Error when setting container resources: {0}&#34;.format(str(e)), self.debug)
            return False

    def check_host_cpu_limits(self):
        errors_detected = False
        for host in self.host_info_cache.values():
            all_accounted_shares = 0
            map = host[&#34;resources&#34;][&#34;cpu&#34;][&#34;core_usage_mapping&#34;]
            for core in map.values():
                for container in core:
                    if container != &#34;free&#34;:
                        all_accounted_shares += core[container]
            if all_accounted_shares &gt; host[&#34;resources&#34;][&#34;cpu&#34;][&#34;max&#34;]:
                log_error(&#34;Host {0} has more mapped shares than its maximum&#34;.format(host[&#34;name&#34;]), self.debug)
                errors_detected = True
        return errors_detected

    def check_host_has_enough_free_resources(self, host_info, needed_resources, resource):
        host_shares = host_info[&#34;resources&#34;][resource][&#34;free&#34;]
        if host_shares == 0:
            raise ValueError(&#34;No resources available for resource {0} in host {1} &#34;.format(resource, host_info[&#34;name&#34;]))
        elif host_shares &lt; needed_resources:
            missing_shares = needed_resources - host_shares
            # raise ValueError(&#34;Error in setting {0}, couldn&#39;t get the resources needed, missing {1} shares&#34;.format(resource, missing_shares))
            log_warning(
                &#34;Beware, there are not enough free shares for resource {0} in the host, there are {1},  missing {2}&#34;.format(resource, host_shares, missing_shares),
                self.debug)

    def check_containers_cpu_limits(self, containers):
        errors_detected = False
        for container in containers:
            database_resources = container[&#34;resources&#34;]

            if &#34;max&#34; not in database_resources[&#34;cpu&#34;]:
                log_error(&#34;container {0} has not a maximum value set, check its configuration&#34;.format(container[&#34;name&#34;]), self.debug)
                errors_detected = True
                continue

            max_cpu_limit = database_resources[&#34;cpu&#34;][&#34;max&#34;]
            real_resources = self.container_info_cache[container[&#34;name&#34;]][&#34;resources&#34;]
            try:
                current_cpu_limit = self.get_current_resource_value(real_resources, &#34;cpu&#34;)
                if current_cpu_limit &gt; max_cpu_limit:
                    log_error(&#34;container {0} has, somehow, more shares ({1}) than the maximum ({2}), check the max &#34;
                              &#34;parameter in its configuration&#34;.format(container[&#34;name&#34;], current_cpu_limit, max_cpu_limit), self.debug)
                    errors_detected = True
            except ValueError as e:
                log_error(&#34;Current value of structure {0} is not valid: {1}&#34;.format(container[&#34;name&#34;], str(e)), self.debug)
                errors_detected = True

        return errors_detected

    def check_container_cpu_mapping(self, container, host_info, cpu_used_cores, cpu_used_shares):
        host_max_cores = int(host_info[&#34;resources&#34;][&#34;cpu&#34;][&#34;max&#34;] / 100)
        host_cpu_list = [str(i) for i in range(host_max_cores)]
        core_usage_map = host_info[&#34;resources&#34;][&#34;cpu&#34;][&#34;core_usage_mapping&#34;]

        cpu_accounted_shares = 0
        cpu_accounted_cores = list()
        container_name = container[&#34;name&#34;]
        for core in core_usage_map:
            if core not in host_cpu_list:
                continue
            if container_name in core_usage_map[core] and core_usage_map[core][container_name] != 0:
                cpu_accounted_shares += core_usage_map[core][container_name]
                cpu_accounted_cores.append(core)

        if sorted(cpu_used_cores) != sorted(cpu_accounted_cores) or cpu_used_shares != cpu_accounted_shares:
            return False, cpu_accounted_cores, cpu_accounted_shares
        else:
            return True, cpu_accounted_cores, cpu_accounted_shares

    def check_container_core_mapping(self, container, real_resources):
        errors_detected = False
        database_resources = container[&#34;resources&#34;]

        if container[&#34;host&#34;] not in self.host_info_cache:
            log_error(&#34;Host info &#39;{0}&#39; for container {1} is missing&#34;.format(container[&#34;host&#34;], container[&#34;name&#34;]), self.debug)
            return True
        elif &#34;max&#34; not in database_resources[&#34;cpu&#34;]:
            # This error should have been previously detected
            return True
        else:
            try:
                current_cpu_limit = self.get_current_resource_value(real_resources, &#34;cpu&#34;)
            except ValueError as e:
                log_error(e, self.debug)
                return True

        host_info = self.host_info_cache[container[&#34;host&#34;]]
        max_cpu_limit = database_resources[&#34;cpu&#34;][&#34;max&#34;]
        cpu_list = self.get_cpu_list(real_resources[&#34;cpu&#34;][&#34;cpu_num&#34;])
        c_name = container[&#34;name&#34;]

        map_host_valid, actual_used_cores, actual_used_shares = self.check_container_cpu_mapping(container, host_info, cpu_list, current_cpu_limit)

        if not map_host_valid:
            log_error(
                &#34;Detected invalid core mapping for container {0}, has {1}-{2}, should be {3}-{4}&#34;.format(c_name, cpu_list, current_cpu_limit, actual_used_cores, actual_used_shares),
                self.debug)
            log_error(&#34;trying to automatically fix&#34;, self.debug)
            success = self.fix_container_cpu_mapping(container, actual_used_cores, actual_used_shares)
            if success:
                log_error(&#34;Succeeded fixing {0} container&#39;s core mapping&#34;.format(container[&#34;name&#34;]), self.debug)
                errors_detected = True
            else:
                log_error(&#34;Failed in fixing {0} container&#39;s core mapping&#34;.format(container[&#34;name&#34;]), self.debug)
                errors_detected = False
        return errors_detected

    def check_core_mapping(self, containers):
        errors_detected = False
        for container in containers:
            c_name = container[&#34;name&#34;]
            log_info(&#34;Checking container {0}&#34;.format(c_name), self.debug)
            if c_name not in self.container_info_cache or &#34;resources&#34; not in self.container_info_cache[c_name]:
                log_error(&#34;Couldn&#39;t get container&#39;s {0} resources, can&#39;t check its sanity&#34;.format(c_name), self.debug)
                continue
            real_resources = self.container_info_cache[c_name][&#34;resources&#34;]
            errors = self.check_container_core_mapping(container, real_resources)
            errors_detected = errors_detected or errors
        return errors_detected

    def check_invalid_resource_value(self, database_resources, amount, current, resource):
        max_resource_limit = int(database_resources[&#34;resources&#34;][resource][&#34;max&#34;])
        min_resource_limit = int(database_resources[&#34;resources&#34;][resource][&#34;min&#34;])
        resource_limit = int(current + amount)

        if resource_limit &lt; 0:
            raise ValueError(&#34;Error in setting {0}, it would be lower than 0&#34;.format(resource))
        elif resource_limit &lt; min_resource_limit:
            raise ValueError(&#34;Error in setting {0}, new value {1} it would be lower than min {2}&#34;.format(resource, resource_limit, min_resource_limit))
        elif resource_limit &gt; max_resource_limit:
            raise ValueError(&#34;Error in setting {0}, new value {1} it would be higher than max {2}&#34;.format(resource, resource_limit, max_resource_limit))

    ######################################################

    #### REQUEST MANAGEMENT ####
    def filter_requests(self, request_timeout):
        fresh_requests, purged_requests, final_requests = list(), list(), list()
        # Remote database operation
        all_requests = self.db_handler.get_requests()
        purged_counter = 0
        duplicated_counter = 0

        # First purge the old requests
        for request in all_requests:
            if request[&#34;timestamp&#34;] &lt; time.time() - request_timeout:
                purged_requests.append(request)
                purged_counter += 1
            else:
                fresh_requests.append(request)

        # Then remove repeated requests for the same structure if found
        structure_requests_dict = {}
        for request in fresh_requests:
            structure = request[&#34;structure&#34;]  # The structure name (string), acting as an id
            action = request[&#34;action&#34;]  # The action name (string)
            if structure not in structure_requests_dict:
                structure_requests_dict[structure] = {}

            if action not in structure_requests_dict[structure]:
                structure_requests_dict[structure][action] = request
            else:
                # A previous request was found for this structure, remove old one and leave the newer one
                stored_request = structure_requests_dict[structure][action]
                if stored_request[&#34;timestamp&#34;] &gt; request[&#34;timestamp&#34;]:
                    # The stored request is newer, leave it and mark the retrieved one to be removed
                    purged_requests.append(request)
                else:
                    # The stored request is older, mark it to be remove and save the retrieved one
                    purged_requests.append(stored_request)
                    structure_requests_dict[structure][action] = request

                duplicated_counter += 1

        self.db_handler.delete_requests(purged_requests)

        for structure in structure_requests_dict:
            for action in structure_requests_dict[structure]:
                final_requests.append(structure_requests_dict[structure][action])

        log_info(&#34;Number of purged/duplicated requests was {0}/{1}&#34;.format(purged_counter, duplicated_counter), True)
        return final_requests

    def sort_requests(self, new_requests):
        container_reqs, app_reqs = list(), list()
        for r in new_requests:
            if r[&#34;structure_type&#34;] == &#34;container&#34;:
                container_reqs.append(r)
            elif r[&#34;structure_type&#34;] == &#34;application&#34;:
                app_reqs.append(r)
            else:
                pass
        return container_reqs, app_reqs

    ######################################################

    #### RESOURCE REQUEST MANAGEMENT ####
    def process_request(self, request, real_resources, database_resources):
        # Create a &#39;fake&#39; container structure with only the required info
        container = {&#34;host_rescaler_ip&#34;: request[&#34;host_rescaler_ip&#34;],
                     &#34;host_rescaler_port&#34;: request[&#34;host_rescaler_port&#34;],
                     &#34;name&#34;: request[&#34;structure&#34;]}

        # Apply the request and get the new resources to set
        try:
            new_resources = self.apply_request(request, real_resources, database_resources)
            if new_resources:
                log_info(&#34;Request: {0} for container : {1} for new resources : {2}&#34;.format(
                    request[&#34;action&#34;], request[&#34;structure&#34;], json.dumps(new_resources)), self.debug)

                # Apply changes through a REST call
                set_container_resources(self.rescaler_http_session, container, new_resources, self.debug)
        except (ValueError) as e:
            log_error(&#34;Error with container {0} in applying the request -&gt; {1}&#34;.format(request[&#34;structure&#34;], str(e)), self.debug)
            return
        except (HTTPError) as e:
            log_error(&#34;Error setting container {0} resources -&gt; {1}&#34;.format(request[&#34;structure&#34;], str(e)), self.debug)
            return
        except (Exception) as e:
            log_error(&#34;Error with container {0} -&gt; {1}&#34;.format(request[&#34;structure&#34;], str(e)), self.debug)
            return

    def apply_request(self, request, real_resources, database_resources):

        amount = int(request[&#34;amount&#34;])

        host_info = self.host_info_cache[request[&#34;host&#34;]]
        resource = request[&#34;resource&#34;]

        # Get the current resource limit, if unlimited, then max, min or mean
        current_resource_limit = self.get_current_resource_value(real_resources, resource)

        # Check that the resource limit is respected, not lower than min or higher than max
        self.check_invalid_resource_value(database_resources, amount, current_resource_limit, resource)

        if amount &gt; 0:
            # If the request is for scale up, check that the host has enough free resources before proceeding
            self.check_host_has_enough_free_resources(host_info, amount, resource)

        fun = self.apply_request_by_resource[resource]
        result = fun(request, database_resources, real_resources, amount)

        return result

    def apply_cpu_request(self, request, database_resources, real_resources, amount):
        resource = request[&#34;resource&#34;]
        structure_name = request[&#34;structure&#34;]
        host_info = self.host_info_cache[request[&#34;host&#34;]]

        core_usage_map = host_info[&#34;resources&#34;][resource][&#34;core_usage_mapping&#34;]

        current_cpu_limit = self.get_current_resource_value(real_resources, resource)
        cpu_list = self.get_cpu_list(real_resources[&#34;cpu&#34;][&#34;cpu_num&#34;])

        host_max_cores = int(host_info[&#34;resources&#34;][&#34;cpu&#34;][&#34;max&#34;] / 100)
        host_cpu_list = [str(i) for i in range(host_max_cores)]
        for core in host_cpu_list:
            if core not in core_usage_map:
                core_usage_map[core] = dict()
                core_usage_map[core][&#34;free&#34;] = 100
            if structure_name not in core_usage_map[core]:
                core_usage_map[core][structure_name] = 0

        used_cores = list(cpu_list)  # copy

        if amount &gt; 0:
            # Rescale up, so look for free shares to assign and maybe add cores
            needed_shares = amount

            # First fill the already used cores so that no additional cores are added unnecessarily
            for core in cpu_list:
                if core_usage_map[core][&#34;free&#34;] &gt; 0:
                    if core_usage_map[core][&#34;free&#34;] &gt; needed_shares:
                        core_usage_map[core][&#34;free&#34;] -= needed_shares
                        core_usage_map[core][structure_name] += needed_shares
                        needed_shares = 0
                        break
                    else:
                        core_usage_map[core][structure_name] += core_usage_map[core][&#34;free&#34;]
                        needed_shares -= core_usage_map[core][&#34;free&#34;]
                        core_usage_map[core][&#34;free&#34;] = 0

            # Next try to satisfy the request by looking and adding a single core
            if needed_shares &gt; 0:
                for core in host_cpu_list:
                    if core_usage_map[core][&#34;free&#34;] &gt;= needed_shares:
                        core_usage_map[core][&#34;free&#34;] -= needed_shares
                        core_usage_map[core][structure_name] += needed_shares
                        needed_shares = 0
                        used_cores.append(core)
                        break

            # Finally, if unsuccessful, add as many cores as necessary, starting with the ones with the largest free shares to avoid too much spread
            if needed_shares &gt; 0:
                l = list()
                for core in host_cpu_list:
                    l.append((core, core_usage_map[core][&#34;free&#34;]))
                l.sort(key=lambda tup: tup[1], reverse=True)
                less_used_cores = [i[0] for i in l]

                for core in less_used_cores:
                    # If this core has free shares
                    if core_usage_map[core][&#34;free&#34;] &gt; 0 and needed_shares &gt; 0:
                        # If it has more free shares than needed, assign them and finish
                        if core_usage_map[core][&#34;free&#34;] &gt;= needed_shares:
                            core_usage_map[core][&#34;free&#34;] -= needed_shares
                            core_usage_map[core][structure_name] += needed_shares
                            needed_shares = 0
                            used_cores.append(core)
                            break
                        else:
                            # Otherwise, assign as many as possible and continue
                            core_usage_map[core][structure_name] += core_usage_map[core][&#34;free&#34;]
                            needed_shares -= core_usage_map[core][&#34;free&#34;]
                            core_usage_map[core][&#34;free&#34;] = 0
                            used_cores.append(core)

            if needed_shares &gt; 0:
                # raise ValueError(&#34;Error in setting cpu, couldn&#39;t get the resources needed, missing {0} shares&#34;.format(needed_shares))
                log_warning(&#34;Structure {0} couldn&#39;t get as much CPU shares as intended ({1}), &#34;
                            &#34;instead it got {2}&#34;.format(structure_name, amount, amount - needed_shares), self.debug)
                amount = amount - needed_shares
                # FIXME couldn&#39;t do rescale up properly as shares to get remain

        elif amount &lt; 0:
            # Rescale down so free all shares and claim new one to see how many cores can be freed
            shares_to_free = abs(amount)

            # First try to find cores with less shares for this structure (less allocated) and remove them
            l = list()
            for core in cpu_list:
                l.append((core, core_usage_map[core][structure_name]))
            l.sort(key=lambda tup: tup[1], reverse=False)
            less_allocated_cores = [i[0] for i in l]

            for core in less_allocated_cores:
                # Equal or less allocated shares than amount to be freed, remove this core altogether and if shares remain to be freed, continue
                if core_usage_map[core][structure_name] &lt;= shares_to_free:
                    core_usage_map[core][&#34;free&#34;] += core_usage_map[core][structure_name]
                    shares_to_free -= core_usage_map[core][structure_name]
                    core_usage_map[core][structure_name] = 0
                    used_cores.remove(core)
                    # In the event that the amount to be freed was equal to the allocated one, finish
                    if shares_to_free == 0:
                        break
                # More allocated shares than amount to be freed, reduce allocation and finish
                elif core_usage_map[core][structure_name] &gt; shares_to_free:
                    core_usage_map[core][&#34;free&#34;] += shares_to_free
                    core_usage_map[core][structure_name] -= shares_to_free
                    shares_to_free = 0
                    break

            if shares_to_free &gt; 0:
                raise ValueError(&#34;Error in setting cpu, couldn&#39;t free the resources properly&#34;)

        # No error thrown, so persist the new mapping to the cache
        self.host_info_cache[request[&#34;host&#34;]][&#34;resources&#34;][&#34;cpu&#34;][&#34;core_usage_mapping&#34;] = core_usage_map
        self.host_info_cache[request[&#34;host&#34;]][&#34;resources&#34;][&#34;cpu&#34;][&#34;free&#34;] -= amount

        resource_dict = {resource: {}}
        resource_dict[&#34;cpu&#34;][&#34;cpu_num&#34;] = &#34;,&#34;.join(used_cores)
        resource_dict[&#34;cpu&#34;][&#34;cpu_allowance_limit&#34;] = int(current_cpu_limit + amount)

        return resource_dict

    def apply_mem_request(self, request, database_resources, real_resources, amount):
        resource_dict = {request[&#34;resource&#34;]: {}}
        current_mem_limit = self.get_current_resource_value(real_resources, request[&#34;resource&#34;])

        # No error thrown, so persist the new mapping to the cache
        self.host_info_cache[request[&#34;host&#34;]][&#34;resources&#34;][&#34;mem&#34;][&#34;free&#34;] -= amount

        # Return the dictionary to set the resources
        resource_dict[&#34;mem&#34;][&#34;mem_limit&#34;] = str(int(amount + current_mem_limit))

        return resource_dict

    def apply_disk_request(self, request, database_resources, real_resources, amount):
        resource_dict = {request[&#34;resource&#34;]: {}}
        current_disk_limit = self.get_current_resource_value(real_resources, request[&#34;resource&#34;])

        # Return the dictionary to set the resources
        resource_dict[&#34;disk&#34;][&#34;disk_read_limit&#34;] = str(int(amount + current_disk_limit))
        resource_dict[&#34;disk&#34;][&#34;disk_write_limit&#34;] = str(int(amount + current_disk_limit))

        return resource_dict

    def apply_net_request(self, request, database_resources, real_resources, amount):
        resource_dict = {request[&#34;resource&#34;]: {}}
        current_net_limit = self.get_current_resource_value(real_resources, request[&#34;resource&#34;])

        # Return the dictionary to set the resources
        resource_dict[&#34;net&#34;][&#34;net_limit&#34;] = str(int(amount + current_net_limit))

        return resource_dict

    ######################################################

    ##### CONTAINER SCALING ######
    def rescale_container(self, request, structure):
        try:
            # Needed for the resources reported in the database (the &#39;max, min&#39; values)
            database_resources = structure

            # Get the resources the container is using from its host NodeScaler (the &#39;current&#39; value)
            c_name = structure[&#34;name&#34;]
            if c_name not in self.container_info_cache or &#34;resources&#34; not in self.container_info_cache[c_name]:
                log_error(&#34;Couldn&#39;t get container&#39;s {0} resources, can&#39;t rescale&#34;.format(c_name), self.debug)
                return
            real_resources = self.container_info_cache[c_name][&#34;resources&#34;]

            # Process the request
            self.process_request(request, real_resources, database_resources)
        except Exception as e:
            log_error(str(e) + &#34; &#34; + str(traceback.format_exc()), self.debug)

    ######################################################

    ##### APPLICATION SCALING ######
    def sort_containers_by_usage_margin(self, container1, container2, resource):
        &#34;&#34;&#34;
        Parameters:
            container1: dict -&gt; A container structure
            container2: dict -&gt; A container structure
            resource: str -&gt; the resource to be used for sorting
        Returns:
            The tuple of the containers with the (lowest,highest) margin between resources used and resources set
        &#34;&#34;&#34;
        c1_current_amount = container1[&#34;resources&#34;][resource][&#34;current&#34;]
        c1_usage_amount = container1[&#34;resources&#34;][resource][&#34;usage&#34;]
        c2_current_amount = container2[&#34;resources&#34;][resource][&#34;current&#34;]
        c2_usage_amount = container2[&#34;resources&#34;][resource][&#34;usage&#34;]
        if c1_current_amount - c1_usage_amount &lt; c2_current_amount - c2_usage_amount:
            lowest, highest = container1, container2
        else:
            lowest, highest = container2, container1

        return lowest, highest

    def lowest_current_to_usage_margin(self, container1, container2, resource):
        # Return the container with the lowest margin between resources used and resources set (closest bottleneck)
        lowest, _ = self.sort_containers_by_usage_margin(container1, container2, resource)
        return lowest

    def highest_current_to_usage_margin(self, container1, container2, resource):
        # Return the container with the highest margin between resources used and resources set (lowest use)
        _, highest = self.sort_containers_by_usage_margin(container1, container2, resource)
        return highest

    def generate_requests(self, new_requests, app_label):
        rescaled_containers = list()
        total_amount = 0
        for req in new_requests:
            self.db_handler.add_request(req)
            rescaled_containers.append((req[&#34;structure&#34;], req[&#34;amount&#34;]))
            total_amount += req[&#34;amount&#34;]
        log_info(&#34;App {0} rescaled {1} shares by rescaling containers: {2}&#34;.format(app_label, total_amount, str(rescaled_containers)), self.debug)

    def single_container_rescale(self, request, app_containers, resource_usage_cache):
        amount, resource_label = request[&#34;amount&#34;], request[&#34;resource&#34;]
        scalable_containers = list()
        resource_shares = abs(amount)

        # Look for containers that can be rescaled
        for container in app_containers:
            usages = resource_usage_cache[container[&#34;name&#34;]]
            container[&#34;resources&#34;][resource_label][&#34;usage&#34;] = usages[resource_label]
            current_value = container[&#34;resources&#34;][resource_label][&#34;current&#34;]

            # Rescale down
            if amount &lt; 0:
                # Check that the container has enough free resource shares
                # available to be released and that it would be able
                # to be rescaled without dropping under the minimum value
                if current_value &lt; resource_shares:
                    # Container doesn&#39;t have enough resources to free
                    # (&#34;Container doesn&#39;t have enough resources to free&#34;, self.debug)
                    pass
                elif current_value + amount &lt; container[&#34;resources&#34;][resource_label][&#34;min&#34;]:
                    # Container can&#39;t free that amount without dropping under the minimum
                    # log_error(&#34;Container {0} can&#39;t free that amount without dropping under the minimum&#34;.format(container[&#34;name&#34;]), self.debug)
                    pass
                else:
                    scalable_containers.append(container)

            # Rescale up
            else:
                # Check that the container has enough free resource shares available in the host and that it would be able
                # to be rescaled without exceeded the maximum value
                container_host = container[&#34;host&#34;]

                if self.host_info_cache[container_host][&#34;resources&#34;][resource_label][&#34;free&#34;] &lt; resource_shares:
                    # Container&#39;s host doesn&#39;t have enough free resources
                    # log_error(&#34;Container&#39;s host doesn&#39;t have enough free resources&#34;, self.debug)
                    pass
                elif current_value + amount &gt; container[&#34;resources&#34;][resource_label][&#34;max&#34;]:
                    # Container can&#39;t get that amount without exceeding the maximum
                    # log_error(&#34;Container can&#39;t get that amount without exceeding the maximum&#34;, self.debug)
                    pass
                else:
                    scalable_containers.append(container)

        # Look for the best fit container for this resource and launch the rescaling request for it
        if scalable_containers:
            best_fit_container = scalable_containers[0]

            for container in scalable_containers[1:]:
                if amount &lt; 0:
                    # If scaling down, look for containers with usages far from the limit (underuse)
                    best_fit_container = self.highest_current_to_usage_margin(container, best_fit_container, resource_label)
                else:
                    # If scaling up, look for containers with usages close to the limit (bottleneck)
                    best_fit_container = self.lowest_current_to_usage_margin(container, best_fit_container, resource_label)

            # Generate the new request
            new_request = Guardian.generate_request(best_fit_container, amount, resource_label)

            return True, best_fit_container, new_request
        else:
            return False, {}, {}

    def rescale_application(self, request, structure):

        # Get container names that this app uses
        app_containers_names = structure[&#34;containers&#34;]
        app_containers = list()

        for cont_name in app_containers_names:
            # Get the container
            container = self.db_handler.get_structure(cont_name)
            app_containers.append(container)

            # Retrieve host info and cache it in case other containers or applications need it
            if container[&#34;host&#34;] not in self.host_info_cache:
                self.host_info_cache[container[&#34;host&#34;]] = self.db_handler.get_structure(container[&#34;host&#34;])

        total_amount = request[&#34;amount&#34;]

        requests = list()
        remaining_amount = total_amount
        split_amount = APP_SCALING_SPLIT_AMOUNT * (request[&#34;amount&#34;] / abs(request[&#34;amount&#34;]))  # This sets the sign
        request[&#34;amount&#34;] = split_amount

        # Create smaller requests of &#39;split_amount&#39; size
        while abs(remaining_amount) &gt; 0 and abs(remaining_amount) &gt; abs(split_amount):
            requests.append(dict(request))
            remaining_amount -= split_amount

        # If some remaining amount is left, create the last request
        if abs(remaining_amount) &gt; 0:
            request[&#34;amount&#34;] = remaining_amount
            requests.append(dict(request))

        # Get the request usage for all the containers and cache it
        resource_usage_cache = dict()
        for container in app_containers:
            amount, resource = request[&#34;amount&#34;], request[&#34;resource&#34;]
            metrics_to_retrieve = BDWATCHDOG_CONTAINER_METRICS[resource]
            resource_usage_cache[container[&#34;name&#34;]] = self.bdwatchdog_handler.get_structure_timeseries(
                {&#34;host&#34;: container[&#34;name&#34;]}, 10, 20,
                metrics_to_retrieve, RESCALER_CONTAINER_METRICS)

        success, iterations = True, 0
        generated_requests = dict()

        while success and len(requests) &gt; 0:
            request = requests.pop(0)
            success, container_to_rescale, generated_request = self.single_container_rescale(request, app_containers, resource_usage_cache)
            if success:
                # If rescaling was successful, update the container&#39;s resources as they have been rescaled
                for c in app_containers:
                    container_name = c[&#34;name&#34;]
                    if container_name == container_to_rescale[&#34;name&#34;]:
                        # Initialize
                        if container_name not in generated_requests:
                            generated_requests[container_name] = list()

                        generated_requests[container_name].append(generated_request)
                        container_to_rescale[&#34;resources&#34;][request[&#34;resource&#34;]][&#34;current&#34;] += request[&#34;amount&#34;]
                        app_containers.remove(c)
                        app_containers.append(container_to_rescale)
                        break
            else:
                break

            iterations += 1

        # Collapse all the requests to generate just 1 per container
        final_requests = list()
        for container in generated_requests:
            # Copy the first request as the base request
            flat_request = dict(generated_requests[container][0])
            flat_request[&#34;amount&#34;] = 0
            for request in generated_requests[container]:
                flat_request[&#34;amount&#34;] += request[&#34;amount&#34;]
            final_requests.append(flat_request)
        self.generate_requests(final_requests, structure[&#34;name&#34;])

        if len(requests) &gt; 0:
            # Couldn&#39;t completely rescale the application as some split of a major rescaling operation could not be completed
            log_warning(&#34;App {0} could not be completely rescaled, only: {1} shares of resource: {2} have been scaled&#34;.format(
                request[&#34;structure&#34;], str(int(iterations * split_amount)), request[&#34;resource&#34;]), self.debug)

    ######################################################

    ### SERVICE METHODS ####
    def invalid_conf(self, config):
        # TODO This code is duplicated on the structures and database snapshoters
        for key, num in [(&#34;POLLING_FREQUENCY&#34;, config.get_value(&#34;POLLING_FREQUENCY&#34;)), (&#34;REQUEST_TIMEOUT&#34;, config.get_value(&#34;REQUEST_TIMEOUT&#34;))]:
            if num &lt; 5:
                return True, &#34;Configuration item &#39;{0}&#39; with a value of &#39;{1}&#39; is likely invalid&#34;.format(key, num)
        return False, &#34;&#34;

    def get_cpu_list(self, cpu_num_string):
        # Translate something like &#39;2-4,7&#39; to [2,3,7]
        cpu_list = list()
        parts = cpu_num_string.split(&#34;,&#34;)
        for part in parts:
            ranges = part.split(&#34;-&#34;)
            if len(ranges) == 1:
                cpu_list.append(ranges[0])
            else:
                for n in range(int(ranges[0]), int(ranges[1]) + 1):
                    cpu_list.append(str(n))
        return cpu_list

    def get_current_resource_value(self, real_resources, resource):
        translation_dict = {&#34;cpu&#34;: &#34;cpu_allowance_limit&#34;, &#34;mem&#34;: &#34;mem_limit&#34;}

        if resource not in translation_dict:
            raise ValueError(&#34;Resource &#39;{0}&#39; unknown&#34;.format(resource))
        else:
            resource_translated = translation_dict[resource]

        if resource not in real_resources:
            raise ValueError(&#34;Resource &#39;{0}&#39; info missing from host&#34;.format(resource))

        if resource_translated not in real_resources[resource]:
            raise ValueError(&#34;Current value for resource &#39;{0}&#39; missing from host resource info&#34;.format(resource))

        current_resource_limit = real_resources[resource][resource_translated]
        if current_resource_limit == -1:
            raise ValueError(&#34;Resource {0} has not a &#39;current&#39; value set, that is, it is unlimited&#34;.format(resource))
        else:
            try:
                current_resource_limit = int(current_resource_limit)
            except ValueError:
                raise ValueError(&#34;Bad current {0} limit value&#34;.format(resource))
        return current_resource_limit

    def process_requests(self, reqs):
        for request in reqs:
            structure_name = request[&#34;structure&#34;]

            # Retrieve structure info
            try:
                structure = self.db_handler.get_structure(structure_name)
            except (requests.exceptions.HTTPError, ValueError):
                log_error(&#34;Error, couldn&#39;t find structure {0} in database&#34;.format(structure_name), self.debug)
                continue

            # Rescale the structure accordingly, whether it is a container or an application
            if structure_is_container(structure):
                self.rescale_container(request, structure)
            elif structure_is_application(structure):
                self.rescale_application(request, structure)
            else:
                log_error(&#34;Unknown type of structure &#39;{0}&#39;&#34;.format(structure[&#34;subtype&#34;]), self.debug)

            # Remove the request from the database
            self.db_handler.delete_request(request)

    def split_requests(self, all_requests):
        scale_down, scale_up = list(), list()
        for request in all_requests:
            if &#34;action&#34; not in request or not request[&#34;action&#34;]:
                continue
            elif request[&#34;action&#34;].endswith(&#34;Down&#34;):
                scale_down.append(request)
            elif request[&#34;action&#34;].endswith(&#34;Up&#34;):
                scale_up.append(request)
        return scale_down, scale_up

    def fill_host_info_cache(self, containers):
        self.host_info_cache = dict()
        for container in containers:
            if container[&#34;host&#34;] not in self.host_info_cache:
                self.host_info_cache[container[&#34;host&#34;]] = self.db_handler.get_structure(container[&#34;host&#34;])
        return

    def persist_new_host_information(self, ):
        def persist_thread(self, host):
            data = self.host_info_cache[host]
            update_structure(data, self.db_handler, self.debug)

        threads = list()
        for host in self.host_info_cache:
            t = Thread(target=persist_thread, args=(self, host,))
            t.start()
            threads.append(t)

        for t in threads:
            t.join()

    def scale_structures(self, new_requests):
        log_info(&#34;Processing requests&#34;, self.debug)

        t0 = time.time()

        # Split the requests between scale down and scale up
        scale_down, scale_up = self.split_requests(new_requests)

        # Process first the requests that free resources, then the one that use them
        self.process_requests(scale_down)
        self.process_requests(scale_up)

        # Persist the new host information
        self.persist_new_host_information()

        t1 = time.time()
        log_info(&#34;It took {0} seconds to process requests&#34;.format(str(&#34;%.2f&#34; % (t1 - t0))), self.debug)

    ######################################################

    def scale(self, ):
        logging.basicConfig(filename=SERVICE_NAME + &#39;.log&#39;, level=logging.INFO)

        myConfig = MyConfig(CONFIG_DEFAULT_VALUES)

        # Remove previous requests
        log_info(&#34;Purging any previous requests&#34;, True)
        self.filter_requests(0)
        log_info(&#34;----------------------\n&#34;, True)

        while True:
            # Remote database operation
            service = get_service(self.db_handler, SERVICE_NAME)

            # Heartbeat
            beat(self.db_handler, SERVICE_NAME)

            # CONFIG
            myConfig.set_config(service[&#34;config&#34;])
            polling_frequency = myConfig.get_value(&#34;POLLING_FREQUENCY&#34;)
            request_timeout = myConfig.get_value(&#34;REQUEST_TIMEOUT&#34;)
            self.debug = myConfig.get_value(&#34;self.debug&#34;)
            CHECK_CORE_MAP = myConfig.get_value(&#34;CHECK_CORE_MAP&#34;)
            SERVICE_IS_ACTIVATED = myConfig.get_value(&#34;ACTIVE&#34;)

            log_info(&#34;----------------------&#34;, self.debug)
            log_info(&#34;Starting Epoch&#34;, self.debug)
            t0 = time.time()

            ## CHECK INVALID CONFIG ##
            # TODO This code is duplicated on the structures and database snapshoters
            invalid, message = self.invalid_conf(myConfig)
            if invalid:
                log_error(message, self.debug)
                time.sleep(polling_frequency)
                if polling_frequency &lt; 5:
                    log_error(&#34;Polling frequency is too short, replacing with DEFAULT value &#39;{0}&#39;&#34;.format(CONFIG_DEFAULT_VALUES[&#34;POLLING_FREQUENCY&#34;]), self.debug)
                    polling_frequency = CONFIG_DEFAULT_VALUES[&#34;POLLING_FREQUENCY&#34;]

                log_info(&#34;----------------------\n&#34;, self.debug)
                time.sleep(polling_frequency)
                continue

            if SERVICE_IS_ACTIVATED:

                # Get the container structures and their resource information as such data is going to be needed
                containers = get_structures(self.db_handler, self.debug, subtype=&#34;container&#34;)
                try:
                    self.container_info_cache = get_container_resources_dict()  # Reset the cache
                except (Exception, RuntimeError) as e:
                    log_error(&#34;Error getting host document, skipping epoch altogether&#34;, self.debug)
                    log_error(str(e), self.debug)
                    time.sleep(polling_frequency)
                    continue

                # Fill the host information cache
                log_info(&#34;Getting host and container info&#34;, self.debug)
                try:
                    self.fill_host_info_cache(containers)
                except (Exception, RuntimeError) as e:
                    log_error(&#34;Error getting host document, skipping epoch altogether&#34;, self.debug)
                    log_error(str(e), self.debug)
                    time.sleep(polling_frequency)
                    continue

                # Do the core mapping check-up
                if CHECK_CORE_MAP:
                    log_info(&#34;Doing container CPU limits check&#34;, self.debug)
                    log_info(&#34;First hosts&#34;, self.debug)
                    errors_detected = self.check_host_cpu_limits()
                    if errors_detected:
                        log_error(&#34;Errors detected during host CPU limits check&#34;, self.debug)

                    log_info(&#34;Second containers&#34;, self.debug)
                    errors_detected = self.check_containers_cpu_limits(containers)
                    if errors_detected:
                        log_error(&#34;Errors detected during container CPU limits check&#34;, self.debug)

                    log_info(&#34;Doing core mapping check&#34;, self.debug)
                    errors_detected = self.check_core_mapping(containers)
                    if errors_detected:
                        log_error(&#34;Errors detected during container CPU map check&#34;, self.debug)
                else:
                    log_warning(&#34;Core map check has been disabled&#34;, self.debug)

                # Get the requests
                new_requests = self.filter_requests(request_timeout)
                container_reqs, app_reqs = self.sort_requests(new_requests)

                # Process first the application requests, as they generate container ones
                if app_reqs:
                    log_info(&#34;Processing applications requests&#34;, self.debug)
                    self.scale_structures(app_reqs)
                else:
                    log_info(&#34;No applications requests&#34;, self.debug)

                # Then process container ones
                if container_reqs:
                    log_info(&#34;Processing container requests&#34;, self.debug)
                    self.scale_structures(container_reqs)
                else:
                    log_info(&#34;No container requests&#34;, self.debug)

                t1 = time.time()
                log_info(&#34;Epoch processed in {0} seconds&#34;.format(str(&#34;%.2f&#34; % (t1 - t0))), self.debug)

            else:
                log_warning(&#34;Scaler service is not activated&#34;, self.debug)

            log_info(&#34;----------------------\n&#34;, self.debug)
            time.sleep(polling_frequency)


def main():
    try:
        scaler = Scaler()
        scaler.scale()
    except Exception as e:
        log_error(&#34;{0} {1}&#34;.format(str(e), str(traceback.format_exc())), debug=True)


if __name__ == &#34;__main__&#34;:
    main()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="src.Scaler.Scaler.main"><code class="name flex">
<span>def <span class="ident">main</span></span>(<span>)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def main():
    try:
        scaler = Scaler()
        scaler.scale()
    except Exception as e:
        log_error(&#34;{0} {1}&#34;.format(str(e), str(traceback.format_exc())), debug=True)</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.set_container_resources"><code class="name flex">
<span>def <span class="ident">set_container_resources</span></span>(<span>rescaler_http_session, container, resources, debug)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_container_resources(rescaler_http_session, container, resources, debug):
    rescaler_ip = container[&#34;host_rescaler_ip&#34;]
    rescaler_port = container[&#34;host_rescaler_port&#34;]
    container_name = container[&#34;name&#34;]
    r = rescaler_http_session.put(
        &#34;http://{0}:{1}/container/{2}&#34;.format(rescaler_ip, rescaler_port, container_name),
        data=json.dumps(resources),
        headers={&#39;Content-Type&#39;: &#39;application/json&#39;, &#39;Accept&#39;: &#39;application/json&#39;})
    if r.status_code == 201:
        return dict(r.json())
    else:
        log_error(str(json.dumps(r.json())), debug)
        r.raise_for_status()</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="src.Scaler.Scaler.Scaler"><code class="flex name class">
<span>class <span class="ident">Scaler</span></span>
</code></dt>
<dd>
<section class="desc"><p>Scaler class that implements the logic for this microservice.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Scaler:
    &#34;&#34;&#34;
    Scaler class that implements the logic for this microservice.
    &#34;&#34;&#34;

    def __init__(self):
        self.couchdb_handler = couchdb.CouchDBServer()
        self.db_handler = couchDB.CouchDBServer()
        self.rescaler_http_session = requests.Session()
        self.bdwatchdog_handler = bdwatchdog.OpenTSDBServer()
        self.host_info_cache = dict()
        self.container_info_cache = dict()
        self.apply_request_by_resource = {&#34;cpu&#34;: self.apply_cpu_request, &#34;mem&#34;: self.apply_mem_request, &#34;disk&#34;: self.apply_disk_request, &#34;net&#34;: self.apply_net_request}

    #### CHECKS ####
    def fix_container_cpu_mapping(self, container, cpu_used_cores, cpu_used_shares):

        resource_dict = {&#34;cpu&#34;: {}}
        resource_dict[&#34;cpu&#34;][&#34;cpu_num&#34;] = &#34;,&#34;.join(cpu_used_cores)
        resource_dict[&#34;cpu&#34;][&#34;cpu_allowance_limit&#34;] = int(cpu_used_shares)
        try:
            # TODO FIX this error should be further diagnosed, in case it affects other modules who use this call too
            set_container_resources(self.rescaler_http_session, container, resource_dict, self.debug)
            return True
        except (Exception, RuntimeError, ValueError, requests.HTTPError) as e:
            log_error(&#34;Error when setting container resources: {0}&#34;.format(str(e)), self.debug)
            return False

    def check_host_cpu_limits(self):
        errors_detected = False
        for host in self.host_info_cache.values():
            all_accounted_shares = 0
            map = host[&#34;resources&#34;][&#34;cpu&#34;][&#34;core_usage_mapping&#34;]
            for core in map.values():
                for container in core:
                    if container != &#34;free&#34;:
                        all_accounted_shares += core[container]
            if all_accounted_shares &gt; host[&#34;resources&#34;][&#34;cpu&#34;][&#34;max&#34;]:
                log_error(&#34;Host {0} has more mapped shares than its maximum&#34;.format(host[&#34;name&#34;]), self.debug)
                errors_detected = True
        return errors_detected

    def check_host_has_enough_free_resources(self, host_info, needed_resources, resource):
        host_shares = host_info[&#34;resources&#34;][resource][&#34;free&#34;]
        if host_shares == 0:
            raise ValueError(&#34;No resources available for resource {0} in host {1} &#34;.format(resource, host_info[&#34;name&#34;]))
        elif host_shares &lt; needed_resources:
            missing_shares = needed_resources - host_shares
            # raise ValueError(&#34;Error in setting {0}, couldn&#39;t get the resources needed, missing {1} shares&#34;.format(resource, missing_shares))
            log_warning(
                &#34;Beware, there are not enough free shares for resource {0} in the host, there are {1},  missing {2}&#34;.format(resource, host_shares, missing_shares),
                self.debug)

    def check_containers_cpu_limits(self, containers):
        errors_detected = False
        for container in containers:
            database_resources = container[&#34;resources&#34;]

            if &#34;max&#34; not in database_resources[&#34;cpu&#34;]:
                log_error(&#34;container {0} has not a maximum value set, check its configuration&#34;.format(container[&#34;name&#34;]), self.debug)
                errors_detected = True
                continue

            max_cpu_limit = database_resources[&#34;cpu&#34;][&#34;max&#34;]
            real_resources = self.container_info_cache[container[&#34;name&#34;]][&#34;resources&#34;]
            try:
                current_cpu_limit = self.get_current_resource_value(real_resources, &#34;cpu&#34;)
                if current_cpu_limit &gt; max_cpu_limit:
                    log_error(&#34;container {0} has, somehow, more shares ({1}) than the maximum ({2}), check the max &#34;
                              &#34;parameter in its configuration&#34;.format(container[&#34;name&#34;], current_cpu_limit, max_cpu_limit), self.debug)
                    errors_detected = True
            except ValueError as e:
                log_error(&#34;Current value of structure {0} is not valid: {1}&#34;.format(container[&#34;name&#34;], str(e)), self.debug)
                errors_detected = True

        return errors_detected

    def check_container_cpu_mapping(self, container, host_info, cpu_used_cores, cpu_used_shares):
        host_max_cores = int(host_info[&#34;resources&#34;][&#34;cpu&#34;][&#34;max&#34;] / 100)
        host_cpu_list = [str(i) for i in range(host_max_cores)]
        core_usage_map = host_info[&#34;resources&#34;][&#34;cpu&#34;][&#34;core_usage_mapping&#34;]

        cpu_accounted_shares = 0
        cpu_accounted_cores = list()
        container_name = container[&#34;name&#34;]
        for core in core_usage_map:
            if core not in host_cpu_list:
                continue
            if container_name in core_usage_map[core] and core_usage_map[core][container_name] != 0:
                cpu_accounted_shares += core_usage_map[core][container_name]
                cpu_accounted_cores.append(core)

        if sorted(cpu_used_cores) != sorted(cpu_accounted_cores) or cpu_used_shares != cpu_accounted_shares:
            return False, cpu_accounted_cores, cpu_accounted_shares
        else:
            return True, cpu_accounted_cores, cpu_accounted_shares

    def check_container_core_mapping(self, container, real_resources):
        errors_detected = False
        database_resources = container[&#34;resources&#34;]

        if container[&#34;host&#34;] not in self.host_info_cache:
            log_error(&#34;Host info &#39;{0}&#39; for container {1} is missing&#34;.format(container[&#34;host&#34;], container[&#34;name&#34;]), self.debug)
            return True
        elif &#34;max&#34; not in database_resources[&#34;cpu&#34;]:
            # This error should have been previously detected
            return True
        else:
            try:
                current_cpu_limit = self.get_current_resource_value(real_resources, &#34;cpu&#34;)
            except ValueError as e:
                log_error(e, self.debug)
                return True

        host_info = self.host_info_cache[container[&#34;host&#34;]]
        max_cpu_limit = database_resources[&#34;cpu&#34;][&#34;max&#34;]
        cpu_list = self.get_cpu_list(real_resources[&#34;cpu&#34;][&#34;cpu_num&#34;])
        c_name = container[&#34;name&#34;]

        map_host_valid, actual_used_cores, actual_used_shares = self.check_container_cpu_mapping(container, host_info, cpu_list, current_cpu_limit)

        if not map_host_valid:
            log_error(
                &#34;Detected invalid core mapping for container {0}, has {1}-{2}, should be {3}-{4}&#34;.format(c_name, cpu_list, current_cpu_limit, actual_used_cores, actual_used_shares),
                self.debug)
            log_error(&#34;trying to automatically fix&#34;, self.debug)
            success = self.fix_container_cpu_mapping(container, actual_used_cores, actual_used_shares)
            if success:
                log_error(&#34;Succeeded fixing {0} container&#39;s core mapping&#34;.format(container[&#34;name&#34;]), self.debug)
                errors_detected = True
            else:
                log_error(&#34;Failed in fixing {0} container&#39;s core mapping&#34;.format(container[&#34;name&#34;]), self.debug)
                errors_detected = False
        return errors_detected

    def check_core_mapping(self, containers):
        errors_detected = False
        for container in containers:
            c_name = container[&#34;name&#34;]
            log_info(&#34;Checking container {0}&#34;.format(c_name), self.debug)
            if c_name not in self.container_info_cache or &#34;resources&#34; not in self.container_info_cache[c_name]:
                log_error(&#34;Couldn&#39;t get container&#39;s {0} resources, can&#39;t check its sanity&#34;.format(c_name), self.debug)
                continue
            real_resources = self.container_info_cache[c_name][&#34;resources&#34;]
            errors = self.check_container_core_mapping(container, real_resources)
            errors_detected = errors_detected or errors
        return errors_detected

    def check_invalid_resource_value(self, database_resources, amount, current, resource):
        max_resource_limit = int(database_resources[&#34;resources&#34;][resource][&#34;max&#34;])
        min_resource_limit = int(database_resources[&#34;resources&#34;][resource][&#34;min&#34;])
        resource_limit = int(current + amount)

        if resource_limit &lt; 0:
            raise ValueError(&#34;Error in setting {0}, it would be lower than 0&#34;.format(resource))
        elif resource_limit &lt; min_resource_limit:
            raise ValueError(&#34;Error in setting {0}, new value {1} it would be lower than min {2}&#34;.format(resource, resource_limit, min_resource_limit))
        elif resource_limit &gt; max_resource_limit:
            raise ValueError(&#34;Error in setting {0}, new value {1} it would be higher than max {2}&#34;.format(resource, resource_limit, max_resource_limit))

    ######################################################

    #### REQUEST MANAGEMENT ####
    def filter_requests(self, request_timeout):
        fresh_requests, purged_requests, final_requests = list(), list(), list()
        # Remote database operation
        all_requests = self.db_handler.get_requests()
        purged_counter = 0
        duplicated_counter = 0

        # First purge the old requests
        for request in all_requests:
            if request[&#34;timestamp&#34;] &lt; time.time() - request_timeout:
                purged_requests.append(request)
                purged_counter += 1
            else:
                fresh_requests.append(request)

        # Then remove repeated requests for the same structure if found
        structure_requests_dict = {}
        for request in fresh_requests:
            structure = request[&#34;structure&#34;]  # The structure name (string), acting as an id
            action = request[&#34;action&#34;]  # The action name (string)
            if structure not in structure_requests_dict:
                structure_requests_dict[structure] = {}

            if action not in structure_requests_dict[structure]:
                structure_requests_dict[structure][action] = request
            else:
                # A previous request was found for this structure, remove old one and leave the newer one
                stored_request = structure_requests_dict[structure][action]
                if stored_request[&#34;timestamp&#34;] &gt; request[&#34;timestamp&#34;]:
                    # The stored request is newer, leave it and mark the retrieved one to be removed
                    purged_requests.append(request)
                else:
                    # The stored request is older, mark it to be remove and save the retrieved one
                    purged_requests.append(stored_request)
                    structure_requests_dict[structure][action] = request

                duplicated_counter += 1

        self.db_handler.delete_requests(purged_requests)

        for structure in structure_requests_dict:
            for action in structure_requests_dict[structure]:
                final_requests.append(structure_requests_dict[structure][action])

        log_info(&#34;Number of purged/duplicated requests was {0}/{1}&#34;.format(purged_counter, duplicated_counter), True)
        return final_requests

    def sort_requests(self, new_requests):
        container_reqs, app_reqs = list(), list()
        for r in new_requests:
            if r[&#34;structure_type&#34;] == &#34;container&#34;:
                container_reqs.append(r)
            elif r[&#34;structure_type&#34;] == &#34;application&#34;:
                app_reqs.append(r)
            else:
                pass
        return container_reqs, app_reqs

    ######################################################

    #### RESOURCE REQUEST MANAGEMENT ####
    def process_request(self, request, real_resources, database_resources):
        # Create a &#39;fake&#39; container structure with only the required info
        container = {&#34;host_rescaler_ip&#34;: request[&#34;host_rescaler_ip&#34;],
                     &#34;host_rescaler_port&#34;: request[&#34;host_rescaler_port&#34;],
                     &#34;name&#34;: request[&#34;structure&#34;]}

        # Apply the request and get the new resources to set
        try:
            new_resources = self.apply_request(request, real_resources, database_resources)
            if new_resources:
                log_info(&#34;Request: {0} for container : {1} for new resources : {2}&#34;.format(
                    request[&#34;action&#34;], request[&#34;structure&#34;], json.dumps(new_resources)), self.debug)

                # Apply changes through a REST call
                set_container_resources(self.rescaler_http_session, container, new_resources, self.debug)
        except (ValueError) as e:
            log_error(&#34;Error with container {0} in applying the request -&gt; {1}&#34;.format(request[&#34;structure&#34;], str(e)), self.debug)
            return
        except (HTTPError) as e:
            log_error(&#34;Error setting container {0} resources -&gt; {1}&#34;.format(request[&#34;structure&#34;], str(e)), self.debug)
            return
        except (Exception) as e:
            log_error(&#34;Error with container {0} -&gt; {1}&#34;.format(request[&#34;structure&#34;], str(e)), self.debug)
            return

    def apply_request(self, request, real_resources, database_resources):

        amount = int(request[&#34;amount&#34;])

        host_info = self.host_info_cache[request[&#34;host&#34;]]
        resource = request[&#34;resource&#34;]

        # Get the current resource limit, if unlimited, then max, min or mean
        current_resource_limit = self.get_current_resource_value(real_resources, resource)

        # Check that the resource limit is respected, not lower than min or higher than max
        self.check_invalid_resource_value(database_resources, amount, current_resource_limit, resource)

        if amount &gt; 0:
            # If the request is for scale up, check that the host has enough free resources before proceeding
            self.check_host_has_enough_free_resources(host_info, amount, resource)

        fun = self.apply_request_by_resource[resource]
        result = fun(request, database_resources, real_resources, amount)

        return result

    def apply_cpu_request(self, request, database_resources, real_resources, amount):
        resource = request[&#34;resource&#34;]
        structure_name = request[&#34;structure&#34;]
        host_info = self.host_info_cache[request[&#34;host&#34;]]

        core_usage_map = host_info[&#34;resources&#34;][resource][&#34;core_usage_mapping&#34;]

        current_cpu_limit = self.get_current_resource_value(real_resources, resource)
        cpu_list = self.get_cpu_list(real_resources[&#34;cpu&#34;][&#34;cpu_num&#34;])

        host_max_cores = int(host_info[&#34;resources&#34;][&#34;cpu&#34;][&#34;max&#34;] / 100)
        host_cpu_list = [str(i) for i in range(host_max_cores)]
        for core in host_cpu_list:
            if core not in core_usage_map:
                core_usage_map[core] = dict()
                core_usage_map[core][&#34;free&#34;] = 100
            if structure_name not in core_usage_map[core]:
                core_usage_map[core][structure_name] = 0

        used_cores = list(cpu_list)  # copy

        if amount &gt; 0:
            # Rescale up, so look for free shares to assign and maybe add cores
            needed_shares = amount

            # First fill the already used cores so that no additional cores are added unnecessarily
            for core in cpu_list:
                if core_usage_map[core][&#34;free&#34;] &gt; 0:
                    if core_usage_map[core][&#34;free&#34;] &gt; needed_shares:
                        core_usage_map[core][&#34;free&#34;] -= needed_shares
                        core_usage_map[core][structure_name] += needed_shares
                        needed_shares = 0
                        break
                    else:
                        core_usage_map[core][structure_name] += core_usage_map[core][&#34;free&#34;]
                        needed_shares -= core_usage_map[core][&#34;free&#34;]
                        core_usage_map[core][&#34;free&#34;] = 0

            # Next try to satisfy the request by looking and adding a single core
            if needed_shares &gt; 0:
                for core in host_cpu_list:
                    if core_usage_map[core][&#34;free&#34;] &gt;= needed_shares:
                        core_usage_map[core][&#34;free&#34;] -= needed_shares
                        core_usage_map[core][structure_name] += needed_shares
                        needed_shares = 0
                        used_cores.append(core)
                        break

            # Finally, if unsuccessful, add as many cores as necessary, starting with the ones with the largest free shares to avoid too much spread
            if needed_shares &gt; 0:
                l = list()
                for core in host_cpu_list:
                    l.append((core, core_usage_map[core][&#34;free&#34;]))
                l.sort(key=lambda tup: tup[1], reverse=True)
                less_used_cores = [i[0] for i in l]

                for core in less_used_cores:
                    # If this core has free shares
                    if core_usage_map[core][&#34;free&#34;] &gt; 0 and needed_shares &gt; 0:
                        # If it has more free shares than needed, assign them and finish
                        if core_usage_map[core][&#34;free&#34;] &gt;= needed_shares:
                            core_usage_map[core][&#34;free&#34;] -= needed_shares
                            core_usage_map[core][structure_name] += needed_shares
                            needed_shares = 0
                            used_cores.append(core)
                            break
                        else:
                            # Otherwise, assign as many as possible and continue
                            core_usage_map[core][structure_name] += core_usage_map[core][&#34;free&#34;]
                            needed_shares -= core_usage_map[core][&#34;free&#34;]
                            core_usage_map[core][&#34;free&#34;] = 0
                            used_cores.append(core)

            if needed_shares &gt; 0:
                # raise ValueError(&#34;Error in setting cpu, couldn&#39;t get the resources needed, missing {0} shares&#34;.format(needed_shares))
                log_warning(&#34;Structure {0} couldn&#39;t get as much CPU shares as intended ({1}), &#34;
                            &#34;instead it got {2}&#34;.format(structure_name, amount, amount - needed_shares), self.debug)
                amount = amount - needed_shares
                # FIXME couldn&#39;t do rescale up properly as shares to get remain

        elif amount &lt; 0:
            # Rescale down so free all shares and claim new one to see how many cores can be freed
            shares_to_free = abs(amount)

            # First try to find cores with less shares for this structure (less allocated) and remove them
            l = list()
            for core in cpu_list:
                l.append((core, core_usage_map[core][structure_name]))
            l.sort(key=lambda tup: tup[1], reverse=False)
            less_allocated_cores = [i[0] for i in l]

            for core in less_allocated_cores:
                # Equal or less allocated shares than amount to be freed, remove this core altogether and if shares remain to be freed, continue
                if core_usage_map[core][structure_name] &lt;= shares_to_free:
                    core_usage_map[core][&#34;free&#34;] += core_usage_map[core][structure_name]
                    shares_to_free -= core_usage_map[core][structure_name]
                    core_usage_map[core][structure_name] = 0
                    used_cores.remove(core)
                    # In the event that the amount to be freed was equal to the allocated one, finish
                    if shares_to_free == 0:
                        break
                # More allocated shares than amount to be freed, reduce allocation and finish
                elif core_usage_map[core][structure_name] &gt; shares_to_free:
                    core_usage_map[core][&#34;free&#34;] += shares_to_free
                    core_usage_map[core][structure_name] -= shares_to_free
                    shares_to_free = 0
                    break

            if shares_to_free &gt; 0:
                raise ValueError(&#34;Error in setting cpu, couldn&#39;t free the resources properly&#34;)

        # No error thrown, so persist the new mapping to the cache
        self.host_info_cache[request[&#34;host&#34;]][&#34;resources&#34;][&#34;cpu&#34;][&#34;core_usage_mapping&#34;] = core_usage_map
        self.host_info_cache[request[&#34;host&#34;]][&#34;resources&#34;][&#34;cpu&#34;][&#34;free&#34;] -= amount

        resource_dict = {resource: {}}
        resource_dict[&#34;cpu&#34;][&#34;cpu_num&#34;] = &#34;,&#34;.join(used_cores)
        resource_dict[&#34;cpu&#34;][&#34;cpu_allowance_limit&#34;] = int(current_cpu_limit + amount)

        return resource_dict

    def apply_mem_request(self, request, database_resources, real_resources, amount):
        resource_dict = {request[&#34;resource&#34;]: {}}
        current_mem_limit = self.get_current_resource_value(real_resources, request[&#34;resource&#34;])

        # No error thrown, so persist the new mapping to the cache
        self.host_info_cache[request[&#34;host&#34;]][&#34;resources&#34;][&#34;mem&#34;][&#34;free&#34;] -= amount

        # Return the dictionary to set the resources
        resource_dict[&#34;mem&#34;][&#34;mem_limit&#34;] = str(int(amount + current_mem_limit))

        return resource_dict

    def apply_disk_request(self, request, database_resources, real_resources, amount):
        resource_dict = {request[&#34;resource&#34;]: {}}
        current_disk_limit = self.get_current_resource_value(real_resources, request[&#34;resource&#34;])

        # Return the dictionary to set the resources
        resource_dict[&#34;disk&#34;][&#34;disk_read_limit&#34;] = str(int(amount + current_disk_limit))
        resource_dict[&#34;disk&#34;][&#34;disk_write_limit&#34;] = str(int(amount + current_disk_limit))

        return resource_dict

    def apply_net_request(self, request, database_resources, real_resources, amount):
        resource_dict = {request[&#34;resource&#34;]: {}}
        current_net_limit = self.get_current_resource_value(real_resources, request[&#34;resource&#34;])

        # Return the dictionary to set the resources
        resource_dict[&#34;net&#34;][&#34;net_limit&#34;] = str(int(amount + current_net_limit))

        return resource_dict

    ######################################################

    ##### CONTAINER SCALING ######
    def rescale_container(self, request, structure):
        try:
            # Needed for the resources reported in the database (the &#39;max, min&#39; values)
            database_resources = structure

            # Get the resources the container is using from its host NodeScaler (the &#39;current&#39; value)
            c_name = structure[&#34;name&#34;]
            if c_name not in self.container_info_cache or &#34;resources&#34; not in self.container_info_cache[c_name]:
                log_error(&#34;Couldn&#39;t get container&#39;s {0} resources, can&#39;t rescale&#34;.format(c_name), self.debug)
                return
            real_resources = self.container_info_cache[c_name][&#34;resources&#34;]

            # Process the request
            self.process_request(request, real_resources, database_resources)
        except Exception as e:
            log_error(str(e) + &#34; &#34; + str(traceback.format_exc()), self.debug)

    ######################################################

    ##### APPLICATION SCALING ######
    def sort_containers_by_usage_margin(self, container1, container2, resource):
        &#34;&#34;&#34;
        Parameters:
            container1: dict -&gt; A container structure
            container2: dict -&gt; A container structure
            resource: str -&gt; the resource to be used for sorting
        Returns:
            The tuple of the containers with the (lowest,highest) margin between resources used and resources set
        &#34;&#34;&#34;
        c1_current_amount = container1[&#34;resources&#34;][resource][&#34;current&#34;]
        c1_usage_amount = container1[&#34;resources&#34;][resource][&#34;usage&#34;]
        c2_current_amount = container2[&#34;resources&#34;][resource][&#34;current&#34;]
        c2_usage_amount = container2[&#34;resources&#34;][resource][&#34;usage&#34;]
        if c1_current_amount - c1_usage_amount &lt; c2_current_amount - c2_usage_amount:
            lowest, highest = container1, container2
        else:
            lowest, highest = container2, container1

        return lowest, highest

    def lowest_current_to_usage_margin(self, container1, container2, resource):
        # Return the container with the lowest margin between resources used and resources set (closest bottleneck)
        lowest, _ = self.sort_containers_by_usage_margin(container1, container2, resource)
        return lowest

    def highest_current_to_usage_margin(self, container1, container2, resource):
        # Return the container with the highest margin between resources used and resources set (lowest use)
        _, highest = self.sort_containers_by_usage_margin(container1, container2, resource)
        return highest

    def generate_requests(self, new_requests, app_label):
        rescaled_containers = list()
        total_amount = 0
        for req in new_requests:
            self.db_handler.add_request(req)
            rescaled_containers.append((req[&#34;structure&#34;], req[&#34;amount&#34;]))
            total_amount += req[&#34;amount&#34;]
        log_info(&#34;App {0} rescaled {1} shares by rescaling containers: {2}&#34;.format(app_label, total_amount, str(rescaled_containers)), self.debug)

    def single_container_rescale(self, request, app_containers, resource_usage_cache):
        amount, resource_label = request[&#34;amount&#34;], request[&#34;resource&#34;]
        scalable_containers = list()
        resource_shares = abs(amount)

        # Look for containers that can be rescaled
        for container in app_containers:
            usages = resource_usage_cache[container[&#34;name&#34;]]
            container[&#34;resources&#34;][resource_label][&#34;usage&#34;] = usages[resource_label]
            current_value = container[&#34;resources&#34;][resource_label][&#34;current&#34;]

            # Rescale down
            if amount &lt; 0:
                # Check that the container has enough free resource shares
                # available to be released and that it would be able
                # to be rescaled without dropping under the minimum value
                if current_value &lt; resource_shares:
                    # Container doesn&#39;t have enough resources to free
                    # (&#34;Container doesn&#39;t have enough resources to free&#34;, self.debug)
                    pass
                elif current_value + amount &lt; container[&#34;resources&#34;][resource_label][&#34;min&#34;]:
                    # Container can&#39;t free that amount without dropping under the minimum
                    # log_error(&#34;Container {0} can&#39;t free that amount without dropping under the minimum&#34;.format(container[&#34;name&#34;]), self.debug)
                    pass
                else:
                    scalable_containers.append(container)

            # Rescale up
            else:
                # Check that the container has enough free resource shares available in the host and that it would be able
                # to be rescaled without exceeded the maximum value
                container_host = container[&#34;host&#34;]

                if self.host_info_cache[container_host][&#34;resources&#34;][resource_label][&#34;free&#34;] &lt; resource_shares:
                    # Container&#39;s host doesn&#39;t have enough free resources
                    # log_error(&#34;Container&#39;s host doesn&#39;t have enough free resources&#34;, self.debug)
                    pass
                elif current_value + amount &gt; container[&#34;resources&#34;][resource_label][&#34;max&#34;]:
                    # Container can&#39;t get that amount without exceeding the maximum
                    # log_error(&#34;Container can&#39;t get that amount without exceeding the maximum&#34;, self.debug)
                    pass
                else:
                    scalable_containers.append(container)

        # Look for the best fit container for this resource and launch the rescaling request for it
        if scalable_containers:
            best_fit_container = scalable_containers[0]

            for container in scalable_containers[1:]:
                if amount &lt; 0:
                    # If scaling down, look for containers with usages far from the limit (underuse)
                    best_fit_container = self.highest_current_to_usage_margin(container, best_fit_container, resource_label)
                else:
                    # If scaling up, look for containers with usages close to the limit (bottleneck)
                    best_fit_container = self.lowest_current_to_usage_margin(container, best_fit_container, resource_label)

            # Generate the new request
            new_request = Guardian.generate_request(best_fit_container, amount, resource_label)

            return True, best_fit_container, new_request
        else:
            return False, {}, {}

    def rescale_application(self, request, structure):

        # Get container names that this app uses
        app_containers_names = structure[&#34;containers&#34;]
        app_containers = list()

        for cont_name in app_containers_names:
            # Get the container
            container = self.db_handler.get_structure(cont_name)
            app_containers.append(container)

            # Retrieve host info and cache it in case other containers or applications need it
            if container[&#34;host&#34;] not in self.host_info_cache:
                self.host_info_cache[container[&#34;host&#34;]] = self.db_handler.get_structure(container[&#34;host&#34;])

        total_amount = request[&#34;amount&#34;]

        requests = list()
        remaining_amount = total_amount
        split_amount = APP_SCALING_SPLIT_AMOUNT * (request[&#34;amount&#34;] / abs(request[&#34;amount&#34;]))  # This sets the sign
        request[&#34;amount&#34;] = split_amount

        # Create smaller requests of &#39;split_amount&#39; size
        while abs(remaining_amount) &gt; 0 and abs(remaining_amount) &gt; abs(split_amount):
            requests.append(dict(request))
            remaining_amount -= split_amount

        # If some remaining amount is left, create the last request
        if abs(remaining_amount) &gt; 0:
            request[&#34;amount&#34;] = remaining_amount
            requests.append(dict(request))

        # Get the request usage for all the containers and cache it
        resource_usage_cache = dict()
        for container in app_containers:
            amount, resource = request[&#34;amount&#34;], request[&#34;resource&#34;]
            metrics_to_retrieve = BDWATCHDOG_CONTAINER_METRICS[resource]
            resource_usage_cache[container[&#34;name&#34;]] = self.bdwatchdog_handler.get_structure_timeseries(
                {&#34;host&#34;: container[&#34;name&#34;]}, 10, 20,
                metrics_to_retrieve, RESCALER_CONTAINER_METRICS)

        success, iterations = True, 0
        generated_requests = dict()

        while success and len(requests) &gt; 0:
            request = requests.pop(0)
            success, container_to_rescale, generated_request = self.single_container_rescale(request, app_containers, resource_usage_cache)
            if success:
                # If rescaling was successful, update the container&#39;s resources as they have been rescaled
                for c in app_containers:
                    container_name = c[&#34;name&#34;]
                    if container_name == container_to_rescale[&#34;name&#34;]:
                        # Initialize
                        if container_name not in generated_requests:
                            generated_requests[container_name] = list()

                        generated_requests[container_name].append(generated_request)
                        container_to_rescale[&#34;resources&#34;][request[&#34;resource&#34;]][&#34;current&#34;] += request[&#34;amount&#34;]
                        app_containers.remove(c)
                        app_containers.append(container_to_rescale)
                        break
            else:
                break

            iterations += 1

        # Collapse all the requests to generate just 1 per container
        final_requests = list()
        for container in generated_requests:
            # Copy the first request as the base request
            flat_request = dict(generated_requests[container][0])
            flat_request[&#34;amount&#34;] = 0
            for request in generated_requests[container]:
                flat_request[&#34;amount&#34;] += request[&#34;amount&#34;]
            final_requests.append(flat_request)
        self.generate_requests(final_requests, structure[&#34;name&#34;])

        if len(requests) &gt; 0:
            # Couldn&#39;t completely rescale the application as some split of a major rescaling operation could not be completed
            log_warning(&#34;App {0} could not be completely rescaled, only: {1} shares of resource: {2} have been scaled&#34;.format(
                request[&#34;structure&#34;], str(int(iterations * split_amount)), request[&#34;resource&#34;]), self.debug)

    ######################################################

    ### SERVICE METHODS ####
    def invalid_conf(self, config):
        # TODO This code is duplicated on the structures and database snapshoters
        for key, num in [(&#34;POLLING_FREQUENCY&#34;, config.get_value(&#34;POLLING_FREQUENCY&#34;)), (&#34;REQUEST_TIMEOUT&#34;, config.get_value(&#34;REQUEST_TIMEOUT&#34;))]:
            if num &lt; 5:
                return True, &#34;Configuration item &#39;{0}&#39; with a value of &#39;{1}&#39; is likely invalid&#34;.format(key, num)
        return False, &#34;&#34;

    def get_cpu_list(self, cpu_num_string):
        # Translate something like &#39;2-4,7&#39; to [2,3,7]
        cpu_list = list()
        parts = cpu_num_string.split(&#34;,&#34;)
        for part in parts:
            ranges = part.split(&#34;-&#34;)
            if len(ranges) == 1:
                cpu_list.append(ranges[0])
            else:
                for n in range(int(ranges[0]), int(ranges[1]) + 1):
                    cpu_list.append(str(n))
        return cpu_list

    def get_current_resource_value(self, real_resources, resource):
        translation_dict = {&#34;cpu&#34;: &#34;cpu_allowance_limit&#34;, &#34;mem&#34;: &#34;mem_limit&#34;}

        if resource not in translation_dict:
            raise ValueError(&#34;Resource &#39;{0}&#39; unknown&#34;.format(resource))
        else:
            resource_translated = translation_dict[resource]

        if resource not in real_resources:
            raise ValueError(&#34;Resource &#39;{0}&#39; info missing from host&#34;.format(resource))

        if resource_translated not in real_resources[resource]:
            raise ValueError(&#34;Current value for resource &#39;{0}&#39; missing from host resource info&#34;.format(resource))

        current_resource_limit = real_resources[resource][resource_translated]
        if current_resource_limit == -1:
            raise ValueError(&#34;Resource {0} has not a &#39;current&#39; value set, that is, it is unlimited&#34;.format(resource))
        else:
            try:
                current_resource_limit = int(current_resource_limit)
            except ValueError:
                raise ValueError(&#34;Bad current {0} limit value&#34;.format(resource))
        return current_resource_limit

    def process_requests(self, reqs):
        for request in reqs:
            structure_name = request[&#34;structure&#34;]

            # Retrieve structure info
            try:
                structure = self.db_handler.get_structure(structure_name)
            except (requests.exceptions.HTTPError, ValueError):
                log_error(&#34;Error, couldn&#39;t find structure {0} in database&#34;.format(structure_name), self.debug)
                continue

            # Rescale the structure accordingly, whether it is a container or an application
            if structure_is_container(structure):
                self.rescale_container(request, structure)
            elif structure_is_application(structure):
                self.rescale_application(request, structure)
            else:
                log_error(&#34;Unknown type of structure &#39;{0}&#39;&#34;.format(structure[&#34;subtype&#34;]), self.debug)

            # Remove the request from the database
            self.db_handler.delete_request(request)

    def split_requests(self, all_requests):
        scale_down, scale_up = list(), list()
        for request in all_requests:
            if &#34;action&#34; not in request or not request[&#34;action&#34;]:
                continue
            elif request[&#34;action&#34;].endswith(&#34;Down&#34;):
                scale_down.append(request)
            elif request[&#34;action&#34;].endswith(&#34;Up&#34;):
                scale_up.append(request)
        return scale_down, scale_up

    def fill_host_info_cache(self, containers):
        self.host_info_cache = dict()
        for container in containers:
            if container[&#34;host&#34;] not in self.host_info_cache:
                self.host_info_cache[container[&#34;host&#34;]] = self.db_handler.get_structure(container[&#34;host&#34;])
        return

    def persist_new_host_information(self, ):
        def persist_thread(self, host):
            data = self.host_info_cache[host]
            update_structure(data, self.db_handler, self.debug)

        threads = list()
        for host in self.host_info_cache:
            t = Thread(target=persist_thread, args=(self, host,))
            t.start()
            threads.append(t)

        for t in threads:
            t.join()

    def scale_structures(self, new_requests):
        log_info(&#34;Processing requests&#34;, self.debug)

        t0 = time.time()

        # Split the requests between scale down and scale up
        scale_down, scale_up = self.split_requests(new_requests)

        # Process first the requests that free resources, then the one that use them
        self.process_requests(scale_down)
        self.process_requests(scale_up)

        # Persist the new host information
        self.persist_new_host_information()

        t1 = time.time()
        log_info(&#34;It took {0} seconds to process requests&#34;.format(str(&#34;%.2f&#34; % (t1 - t0))), self.debug)

    ######################################################

    def scale(self, ):
        logging.basicConfig(filename=SERVICE_NAME + &#39;.log&#39;, level=logging.INFO)

        myConfig = MyConfig(CONFIG_DEFAULT_VALUES)

        # Remove previous requests
        log_info(&#34;Purging any previous requests&#34;, True)
        self.filter_requests(0)
        log_info(&#34;----------------------\n&#34;, True)

        while True:
            # Remote database operation
            service = get_service(self.db_handler, SERVICE_NAME)

            # Heartbeat
            beat(self.db_handler, SERVICE_NAME)

            # CONFIG
            myConfig.set_config(service[&#34;config&#34;])
            polling_frequency = myConfig.get_value(&#34;POLLING_FREQUENCY&#34;)
            request_timeout = myConfig.get_value(&#34;REQUEST_TIMEOUT&#34;)
            self.debug = myConfig.get_value(&#34;self.debug&#34;)
            CHECK_CORE_MAP = myConfig.get_value(&#34;CHECK_CORE_MAP&#34;)
            SERVICE_IS_ACTIVATED = myConfig.get_value(&#34;ACTIVE&#34;)

            log_info(&#34;----------------------&#34;, self.debug)
            log_info(&#34;Starting Epoch&#34;, self.debug)
            t0 = time.time()

            ## CHECK INVALID CONFIG ##
            # TODO This code is duplicated on the structures and database snapshoters
            invalid, message = self.invalid_conf(myConfig)
            if invalid:
                log_error(message, self.debug)
                time.sleep(polling_frequency)
                if polling_frequency &lt; 5:
                    log_error(&#34;Polling frequency is too short, replacing with DEFAULT value &#39;{0}&#39;&#34;.format(CONFIG_DEFAULT_VALUES[&#34;POLLING_FREQUENCY&#34;]), self.debug)
                    polling_frequency = CONFIG_DEFAULT_VALUES[&#34;POLLING_FREQUENCY&#34;]

                log_info(&#34;----------------------\n&#34;, self.debug)
                time.sleep(polling_frequency)
                continue

            if SERVICE_IS_ACTIVATED:

                # Get the container structures and their resource information as such data is going to be needed
                containers = get_structures(self.db_handler, self.debug, subtype=&#34;container&#34;)
                try:
                    self.container_info_cache = get_container_resources_dict()  # Reset the cache
                except (Exception, RuntimeError) as e:
                    log_error(&#34;Error getting host document, skipping epoch altogether&#34;, self.debug)
                    log_error(str(e), self.debug)
                    time.sleep(polling_frequency)
                    continue

                # Fill the host information cache
                log_info(&#34;Getting host and container info&#34;, self.debug)
                try:
                    self.fill_host_info_cache(containers)
                except (Exception, RuntimeError) as e:
                    log_error(&#34;Error getting host document, skipping epoch altogether&#34;, self.debug)
                    log_error(str(e), self.debug)
                    time.sleep(polling_frequency)
                    continue

                # Do the core mapping check-up
                if CHECK_CORE_MAP:
                    log_info(&#34;Doing container CPU limits check&#34;, self.debug)
                    log_info(&#34;First hosts&#34;, self.debug)
                    errors_detected = self.check_host_cpu_limits()
                    if errors_detected:
                        log_error(&#34;Errors detected during host CPU limits check&#34;, self.debug)

                    log_info(&#34;Second containers&#34;, self.debug)
                    errors_detected = self.check_containers_cpu_limits(containers)
                    if errors_detected:
                        log_error(&#34;Errors detected during container CPU limits check&#34;, self.debug)

                    log_info(&#34;Doing core mapping check&#34;, self.debug)
                    errors_detected = self.check_core_mapping(containers)
                    if errors_detected:
                        log_error(&#34;Errors detected during container CPU map check&#34;, self.debug)
                else:
                    log_warning(&#34;Core map check has been disabled&#34;, self.debug)

                # Get the requests
                new_requests = self.filter_requests(request_timeout)
                container_reqs, app_reqs = self.sort_requests(new_requests)

                # Process first the application requests, as they generate container ones
                if app_reqs:
                    log_info(&#34;Processing applications requests&#34;, self.debug)
                    self.scale_structures(app_reqs)
                else:
                    log_info(&#34;No applications requests&#34;, self.debug)

                # Then process container ones
                if container_reqs:
                    log_info(&#34;Processing container requests&#34;, self.debug)
                    self.scale_structures(container_reqs)
                else:
                    log_info(&#34;No container requests&#34;, self.debug)

                t1 = time.time()
                log_info(&#34;Epoch processed in {0} seconds&#34;.format(str(&#34;%.2f&#34; % (t1 - t0))), self.debug)

            else:
                log_warning(&#34;Scaler service is not activated&#34;, self.debug)

            log_info(&#34;----------------------\n&#34;, self.debug)
            time.sleep(polling_frequency)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="src.Scaler.Scaler.Scaler.apply_cpu_request"><code class="name flex">
<span>def <span class="ident">apply_cpu_request</span></span>(<span>self, request, database_resources, real_resources, amount)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_cpu_request(self, request, database_resources, real_resources, amount):
    resource = request[&#34;resource&#34;]
    structure_name = request[&#34;structure&#34;]
    host_info = self.host_info_cache[request[&#34;host&#34;]]

    core_usage_map = host_info[&#34;resources&#34;][resource][&#34;core_usage_mapping&#34;]

    current_cpu_limit = self.get_current_resource_value(real_resources, resource)
    cpu_list = self.get_cpu_list(real_resources[&#34;cpu&#34;][&#34;cpu_num&#34;])

    host_max_cores = int(host_info[&#34;resources&#34;][&#34;cpu&#34;][&#34;max&#34;] / 100)
    host_cpu_list = [str(i) for i in range(host_max_cores)]
    for core in host_cpu_list:
        if core not in core_usage_map:
            core_usage_map[core] = dict()
            core_usage_map[core][&#34;free&#34;] = 100
        if structure_name not in core_usage_map[core]:
            core_usage_map[core][structure_name] = 0

    used_cores = list(cpu_list)  # copy

    if amount &gt; 0:
        # Rescale up, so look for free shares to assign and maybe add cores
        needed_shares = amount

        # First fill the already used cores so that no additional cores are added unnecessarily
        for core in cpu_list:
            if core_usage_map[core][&#34;free&#34;] &gt; 0:
                if core_usage_map[core][&#34;free&#34;] &gt; needed_shares:
                    core_usage_map[core][&#34;free&#34;] -= needed_shares
                    core_usage_map[core][structure_name] += needed_shares
                    needed_shares = 0
                    break
                else:
                    core_usage_map[core][structure_name] += core_usage_map[core][&#34;free&#34;]
                    needed_shares -= core_usage_map[core][&#34;free&#34;]
                    core_usage_map[core][&#34;free&#34;] = 0

        # Next try to satisfy the request by looking and adding a single core
        if needed_shares &gt; 0:
            for core in host_cpu_list:
                if core_usage_map[core][&#34;free&#34;] &gt;= needed_shares:
                    core_usage_map[core][&#34;free&#34;] -= needed_shares
                    core_usage_map[core][structure_name] += needed_shares
                    needed_shares = 0
                    used_cores.append(core)
                    break

        # Finally, if unsuccessful, add as many cores as necessary, starting with the ones with the largest free shares to avoid too much spread
        if needed_shares &gt; 0:
            l = list()
            for core in host_cpu_list:
                l.append((core, core_usage_map[core][&#34;free&#34;]))
            l.sort(key=lambda tup: tup[1], reverse=True)
            less_used_cores = [i[0] for i in l]

            for core in less_used_cores:
                # If this core has free shares
                if core_usage_map[core][&#34;free&#34;] &gt; 0 and needed_shares &gt; 0:
                    # If it has more free shares than needed, assign them and finish
                    if core_usage_map[core][&#34;free&#34;] &gt;= needed_shares:
                        core_usage_map[core][&#34;free&#34;] -= needed_shares
                        core_usage_map[core][structure_name] += needed_shares
                        needed_shares = 0
                        used_cores.append(core)
                        break
                    else:
                        # Otherwise, assign as many as possible and continue
                        core_usage_map[core][structure_name] += core_usage_map[core][&#34;free&#34;]
                        needed_shares -= core_usage_map[core][&#34;free&#34;]
                        core_usage_map[core][&#34;free&#34;] = 0
                        used_cores.append(core)

        if needed_shares &gt; 0:
            # raise ValueError(&#34;Error in setting cpu, couldn&#39;t get the resources needed, missing {0} shares&#34;.format(needed_shares))
            log_warning(&#34;Structure {0} couldn&#39;t get as much CPU shares as intended ({1}), &#34;
                        &#34;instead it got {2}&#34;.format(structure_name, amount, amount - needed_shares), self.debug)
            amount = amount - needed_shares
            # FIXME couldn&#39;t do rescale up properly as shares to get remain

    elif amount &lt; 0:
        # Rescale down so free all shares and claim new one to see how many cores can be freed
        shares_to_free = abs(amount)

        # First try to find cores with less shares for this structure (less allocated) and remove them
        l = list()
        for core in cpu_list:
            l.append((core, core_usage_map[core][structure_name]))
        l.sort(key=lambda tup: tup[1], reverse=False)
        less_allocated_cores = [i[0] for i in l]

        for core in less_allocated_cores:
            # Equal or less allocated shares than amount to be freed, remove this core altogether and if shares remain to be freed, continue
            if core_usage_map[core][structure_name] &lt;= shares_to_free:
                core_usage_map[core][&#34;free&#34;] += core_usage_map[core][structure_name]
                shares_to_free -= core_usage_map[core][structure_name]
                core_usage_map[core][structure_name] = 0
                used_cores.remove(core)
                # In the event that the amount to be freed was equal to the allocated one, finish
                if shares_to_free == 0:
                    break
            # More allocated shares than amount to be freed, reduce allocation and finish
            elif core_usage_map[core][structure_name] &gt; shares_to_free:
                core_usage_map[core][&#34;free&#34;] += shares_to_free
                core_usage_map[core][structure_name] -= shares_to_free
                shares_to_free = 0
                break

        if shares_to_free &gt; 0:
            raise ValueError(&#34;Error in setting cpu, couldn&#39;t free the resources properly&#34;)

    # No error thrown, so persist the new mapping to the cache
    self.host_info_cache[request[&#34;host&#34;]][&#34;resources&#34;][&#34;cpu&#34;][&#34;core_usage_mapping&#34;] = core_usage_map
    self.host_info_cache[request[&#34;host&#34;]][&#34;resources&#34;][&#34;cpu&#34;][&#34;free&#34;] -= amount

    resource_dict = {resource: {}}
    resource_dict[&#34;cpu&#34;][&#34;cpu_num&#34;] = &#34;,&#34;.join(used_cores)
    resource_dict[&#34;cpu&#34;][&#34;cpu_allowance_limit&#34;] = int(current_cpu_limit + amount)

    return resource_dict</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.apply_disk_request"><code class="name flex">
<span>def <span class="ident">apply_disk_request</span></span>(<span>self, request, database_resources, real_resources, amount)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_disk_request(self, request, database_resources, real_resources, amount):
    resource_dict = {request[&#34;resource&#34;]: {}}
    current_disk_limit = self.get_current_resource_value(real_resources, request[&#34;resource&#34;])

    # Return the dictionary to set the resources
    resource_dict[&#34;disk&#34;][&#34;disk_read_limit&#34;] = str(int(amount + current_disk_limit))
    resource_dict[&#34;disk&#34;][&#34;disk_write_limit&#34;] = str(int(amount + current_disk_limit))

    return resource_dict</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.apply_mem_request"><code class="name flex">
<span>def <span class="ident">apply_mem_request</span></span>(<span>self, request, database_resources, real_resources, amount)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_mem_request(self, request, database_resources, real_resources, amount):
    resource_dict = {request[&#34;resource&#34;]: {}}
    current_mem_limit = self.get_current_resource_value(real_resources, request[&#34;resource&#34;])

    # No error thrown, so persist the new mapping to the cache
    self.host_info_cache[request[&#34;host&#34;]][&#34;resources&#34;][&#34;mem&#34;][&#34;free&#34;] -= amount

    # Return the dictionary to set the resources
    resource_dict[&#34;mem&#34;][&#34;mem_limit&#34;] = str(int(amount + current_mem_limit))

    return resource_dict</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.apply_net_request"><code class="name flex">
<span>def <span class="ident">apply_net_request</span></span>(<span>self, request, database_resources, real_resources, amount)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_net_request(self, request, database_resources, real_resources, amount):
    resource_dict = {request[&#34;resource&#34;]: {}}
    current_net_limit = self.get_current_resource_value(real_resources, request[&#34;resource&#34;])

    # Return the dictionary to set the resources
    resource_dict[&#34;net&#34;][&#34;net_limit&#34;] = str(int(amount + current_net_limit))

    return resource_dict</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.apply_request"><code class="name flex">
<span>def <span class="ident">apply_request</span></span>(<span>self, request, real_resources, database_resources)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_request(self, request, real_resources, database_resources):

    amount = int(request[&#34;amount&#34;])

    host_info = self.host_info_cache[request[&#34;host&#34;]]
    resource = request[&#34;resource&#34;]

    # Get the current resource limit, if unlimited, then max, min or mean
    current_resource_limit = self.get_current_resource_value(real_resources, resource)

    # Check that the resource limit is respected, not lower than min or higher than max
    self.check_invalid_resource_value(database_resources, amount, current_resource_limit, resource)

    if amount &gt; 0:
        # If the request is for scale up, check that the host has enough free resources before proceeding
        self.check_host_has_enough_free_resources(host_info, amount, resource)

    fun = self.apply_request_by_resource[resource]
    result = fun(request, database_resources, real_resources, amount)

    return result</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.check_container_core_mapping"><code class="name flex">
<span>def <span class="ident">check_container_core_mapping</span></span>(<span>self, container, real_resources)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_container_core_mapping(self, container, real_resources):
    errors_detected = False
    database_resources = container[&#34;resources&#34;]

    if container[&#34;host&#34;] not in self.host_info_cache:
        log_error(&#34;Host info &#39;{0}&#39; for container {1} is missing&#34;.format(container[&#34;host&#34;], container[&#34;name&#34;]), self.debug)
        return True
    elif &#34;max&#34; not in database_resources[&#34;cpu&#34;]:
        # This error should have been previously detected
        return True
    else:
        try:
            current_cpu_limit = self.get_current_resource_value(real_resources, &#34;cpu&#34;)
        except ValueError as e:
            log_error(e, self.debug)
            return True

    host_info = self.host_info_cache[container[&#34;host&#34;]]
    max_cpu_limit = database_resources[&#34;cpu&#34;][&#34;max&#34;]
    cpu_list = self.get_cpu_list(real_resources[&#34;cpu&#34;][&#34;cpu_num&#34;])
    c_name = container[&#34;name&#34;]

    map_host_valid, actual_used_cores, actual_used_shares = self.check_container_cpu_mapping(container, host_info, cpu_list, current_cpu_limit)

    if not map_host_valid:
        log_error(
            &#34;Detected invalid core mapping for container {0}, has {1}-{2}, should be {3}-{4}&#34;.format(c_name, cpu_list, current_cpu_limit, actual_used_cores, actual_used_shares),
            self.debug)
        log_error(&#34;trying to automatically fix&#34;, self.debug)
        success = self.fix_container_cpu_mapping(container, actual_used_cores, actual_used_shares)
        if success:
            log_error(&#34;Succeeded fixing {0} container&#39;s core mapping&#34;.format(container[&#34;name&#34;]), self.debug)
            errors_detected = True
        else:
            log_error(&#34;Failed in fixing {0} container&#39;s core mapping&#34;.format(container[&#34;name&#34;]), self.debug)
            errors_detected = False
    return errors_detected</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.check_container_cpu_mapping"><code class="name flex">
<span>def <span class="ident">check_container_cpu_mapping</span></span>(<span>self, container, host_info, cpu_used_cores, cpu_used_shares)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_container_cpu_mapping(self, container, host_info, cpu_used_cores, cpu_used_shares):
    host_max_cores = int(host_info[&#34;resources&#34;][&#34;cpu&#34;][&#34;max&#34;] / 100)
    host_cpu_list = [str(i) for i in range(host_max_cores)]
    core_usage_map = host_info[&#34;resources&#34;][&#34;cpu&#34;][&#34;core_usage_mapping&#34;]

    cpu_accounted_shares = 0
    cpu_accounted_cores = list()
    container_name = container[&#34;name&#34;]
    for core in core_usage_map:
        if core not in host_cpu_list:
            continue
        if container_name in core_usage_map[core] and core_usage_map[core][container_name] != 0:
            cpu_accounted_shares += core_usage_map[core][container_name]
            cpu_accounted_cores.append(core)

    if sorted(cpu_used_cores) != sorted(cpu_accounted_cores) or cpu_used_shares != cpu_accounted_shares:
        return False, cpu_accounted_cores, cpu_accounted_shares
    else:
        return True, cpu_accounted_cores, cpu_accounted_shares</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.check_containers_cpu_limits"><code class="name flex">
<span>def <span class="ident">check_containers_cpu_limits</span></span>(<span>self, containers)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_containers_cpu_limits(self, containers):
    errors_detected = False
    for container in containers:
        database_resources = container[&#34;resources&#34;]

        if &#34;max&#34; not in database_resources[&#34;cpu&#34;]:
            log_error(&#34;container {0} has not a maximum value set, check its configuration&#34;.format(container[&#34;name&#34;]), self.debug)
            errors_detected = True
            continue

        max_cpu_limit = database_resources[&#34;cpu&#34;][&#34;max&#34;]
        real_resources = self.container_info_cache[container[&#34;name&#34;]][&#34;resources&#34;]
        try:
            current_cpu_limit = self.get_current_resource_value(real_resources, &#34;cpu&#34;)
            if current_cpu_limit &gt; max_cpu_limit:
                log_error(&#34;container {0} has, somehow, more shares ({1}) than the maximum ({2}), check the max &#34;
                          &#34;parameter in its configuration&#34;.format(container[&#34;name&#34;], current_cpu_limit, max_cpu_limit), self.debug)
                errors_detected = True
        except ValueError as e:
            log_error(&#34;Current value of structure {0} is not valid: {1}&#34;.format(container[&#34;name&#34;], str(e)), self.debug)
            errors_detected = True

    return errors_detected</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.check_core_mapping"><code class="name flex">
<span>def <span class="ident">check_core_mapping</span></span>(<span>self, containers)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_core_mapping(self, containers):
    errors_detected = False
    for container in containers:
        c_name = container[&#34;name&#34;]
        log_info(&#34;Checking container {0}&#34;.format(c_name), self.debug)
        if c_name not in self.container_info_cache or &#34;resources&#34; not in self.container_info_cache[c_name]:
            log_error(&#34;Couldn&#39;t get container&#39;s {0} resources, can&#39;t check its sanity&#34;.format(c_name), self.debug)
            continue
        real_resources = self.container_info_cache[c_name][&#34;resources&#34;]
        errors = self.check_container_core_mapping(container, real_resources)
        errors_detected = errors_detected or errors
    return errors_detected</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.check_host_cpu_limits"><code class="name flex">
<span>def <span class="ident">check_host_cpu_limits</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_host_cpu_limits(self):
    errors_detected = False
    for host in self.host_info_cache.values():
        all_accounted_shares = 0
        map = host[&#34;resources&#34;][&#34;cpu&#34;][&#34;core_usage_mapping&#34;]
        for core in map.values():
            for container in core:
                if container != &#34;free&#34;:
                    all_accounted_shares += core[container]
        if all_accounted_shares &gt; host[&#34;resources&#34;][&#34;cpu&#34;][&#34;max&#34;]:
            log_error(&#34;Host {0} has more mapped shares than its maximum&#34;.format(host[&#34;name&#34;]), self.debug)
            errors_detected = True
    return errors_detected</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.check_host_has_enough_free_resources"><code class="name flex">
<span>def <span class="ident">check_host_has_enough_free_resources</span></span>(<span>self, host_info, needed_resources, resource)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_host_has_enough_free_resources(self, host_info, needed_resources, resource):
    host_shares = host_info[&#34;resources&#34;][resource][&#34;free&#34;]
    if host_shares == 0:
        raise ValueError(&#34;No resources available for resource {0} in host {1} &#34;.format(resource, host_info[&#34;name&#34;]))
    elif host_shares &lt; needed_resources:
        missing_shares = needed_resources - host_shares
        # raise ValueError(&#34;Error in setting {0}, couldn&#39;t get the resources needed, missing {1} shares&#34;.format(resource, missing_shares))
        log_warning(
            &#34;Beware, there are not enough free shares for resource {0} in the host, there are {1},  missing {2}&#34;.format(resource, host_shares, missing_shares),
            self.debug)</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.check_invalid_resource_value"><code class="name flex">
<span>def <span class="ident">check_invalid_resource_value</span></span>(<span>self, database_resources, amount, current, resource)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_invalid_resource_value(self, database_resources, amount, current, resource):
    max_resource_limit = int(database_resources[&#34;resources&#34;][resource][&#34;max&#34;])
    min_resource_limit = int(database_resources[&#34;resources&#34;][resource][&#34;min&#34;])
    resource_limit = int(current + amount)

    if resource_limit &lt; 0:
        raise ValueError(&#34;Error in setting {0}, it would be lower than 0&#34;.format(resource))
    elif resource_limit &lt; min_resource_limit:
        raise ValueError(&#34;Error in setting {0}, new value {1} it would be lower than min {2}&#34;.format(resource, resource_limit, min_resource_limit))
    elif resource_limit &gt; max_resource_limit:
        raise ValueError(&#34;Error in setting {0}, new value {1} it would be higher than max {2}&#34;.format(resource, resource_limit, max_resource_limit))</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.fill_host_info_cache"><code class="name flex">
<span>def <span class="ident">fill_host_info_cache</span></span>(<span>self, containers)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fill_host_info_cache(self, containers):
    self.host_info_cache = dict()
    for container in containers:
        if container[&#34;host&#34;] not in self.host_info_cache:
            self.host_info_cache[container[&#34;host&#34;]] = self.db_handler.get_structure(container[&#34;host&#34;])
    return</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.filter_requests"><code class="name flex">
<span>def <span class="ident">filter_requests</span></span>(<span>self, request_timeout)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def filter_requests(self, request_timeout):
    fresh_requests, purged_requests, final_requests = list(), list(), list()
    # Remote database operation
    all_requests = self.db_handler.get_requests()
    purged_counter = 0
    duplicated_counter = 0

    # First purge the old requests
    for request in all_requests:
        if request[&#34;timestamp&#34;] &lt; time.time() - request_timeout:
            purged_requests.append(request)
            purged_counter += 1
        else:
            fresh_requests.append(request)

    # Then remove repeated requests for the same structure if found
    structure_requests_dict = {}
    for request in fresh_requests:
        structure = request[&#34;structure&#34;]  # The structure name (string), acting as an id
        action = request[&#34;action&#34;]  # The action name (string)
        if structure not in structure_requests_dict:
            structure_requests_dict[structure] = {}

        if action not in structure_requests_dict[structure]:
            structure_requests_dict[structure][action] = request
        else:
            # A previous request was found for this structure, remove old one and leave the newer one
            stored_request = structure_requests_dict[structure][action]
            if stored_request[&#34;timestamp&#34;] &gt; request[&#34;timestamp&#34;]:
                # The stored request is newer, leave it and mark the retrieved one to be removed
                purged_requests.append(request)
            else:
                # The stored request is older, mark it to be remove and save the retrieved one
                purged_requests.append(stored_request)
                structure_requests_dict[structure][action] = request

            duplicated_counter += 1

    self.db_handler.delete_requests(purged_requests)

    for structure in structure_requests_dict:
        for action in structure_requests_dict[structure]:
            final_requests.append(structure_requests_dict[structure][action])

    log_info(&#34;Number of purged/duplicated requests was {0}/{1}&#34;.format(purged_counter, duplicated_counter), True)
    return final_requests</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.fix_container_cpu_mapping"><code class="name flex">
<span>def <span class="ident">fix_container_cpu_mapping</span></span>(<span>self, container, cpu_used_cores, cpu_used_shares)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fix_container_cpu_mapping(self, container, cpu_used_cores, cpu_used_shares):

    resource_dict = {&#34;cpu&#34;: {}}
    resource_dict[&#34;cpu&#34;][&#34;cpu_num&#34;] = &#34;,&#34;.join(cpu_used_cores)
    resource_dict[&#34;cpu&#34;][&#34;cpu_allowance_limit&#34;] = int(cpu_used_shares)
    try:
        # TODO FIX this error should be further diagnosed, in case it affects other modules who use this call too
        set_container_resources(self.rescaler_http_session, container, resource_dict, self.debug)
        return True
    except (Exception, RuntimeError, ValueError, requests.HTTPError) as e:
        log_error(&#34;Error when setting container resources: {0}&#34;.format(str(e)), self.debug)
        return False</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.generate_requests"><code class="name flex">
<span>def <span class="ident">generate_requests</span></span>(<span>self, new_requests, app_label)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_requests(self, new_requests, app_label):
    rescaled_containers = list()
    total_amount = 0
    for req in new_requests:
        self.db_handler.add_request(req)
        rescaled_containers.append((req[&#34;structure&#34;], req[&#34;amount&#34;]))
        total_amount += req[&#34;amount&#34;]
    log_info(&#34;App {0} rescaled {1} shares by rescaling containers: {2}&#34;.format(app_label, total_amount, str(rescaled_containers)), self.debug)</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.get_cpu_list"><code class="name flex">
<span>def <span class="ident">get_cpu_list</span></span>(<span>self, cpu_num_string)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_cpu_list(self, cpu_num_string):
    # Translate something like &#39;2-4,7&#39; to [2,3,7]
    cpu_list = list()
    parts = cpu_num_string.split(&#34;,&#34;)
    for part in parts:
        ranges = part.split(&#34;-&#34;)
        if len(ranges) == 1:
            cpu_list.append(ranges[0])
        else:
            for n in range(int(ranges[0]), int(ranges[1]) + 1):
                cpu_list.append(str(n))
    return cpu_list</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.get_current_resource_value"><code class="name flex">
<span>def <span class="ident">get_current_resource_value</span></span>(<span>self, real_resources, resource)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_current_resource_value(self, real_resources, resource):
    translation_dict = {&#34;cpu&#34;: &#34;cpu_allowance_limit&#34;, &#34;mem&#34;: &#34;mem_limit&#34;}

    if resource not in translation_dict:
        raise ValueError(&#34;Resource &#39;{0}&#39; unknown&#34;.format(resource))
    else:
        resource_translated = translation_dict[resource]

    if resource not in real_resources:
        raise ValueError(&#34;Resource &#39;{0}&#39; info missing from host&#34;.format(resource))

    if resource_translated not in real_resources[resource]:
        raise ValueError(&#34;Current value for resource &#39;{0}&#39; missing from host resource info&#34;.format(resource))

    current_resource_limit = real_resources[resource][resource_translated]
    if current_resource_limit == -1:
        raise ValueError(&#34;Resource {0} has not a &#39;current&#39; value set, that is, it is unlimited&#34;.format(resource))
    else:
        try:
            current_resource_limit = int(current_resource_limit)
        except ValueError:
            raise ValueError(&#34;Bad current {0} limit value&#34;.format(resource))
    return current_resource_limit</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.highest_current_to_usage_margin"><code class="name flex">
<span>def <span class="ident">highest_current_to_usage_margin</span></span>(<span>self, container1, container2, resource)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def highest_current_to_usage_margin(self, container1, container2, resource):
    # Return the container with the highest margin between resources used and resources set (lowest use)
    _, highest = self.sort_containers_by_usage_margin(container1, container2, resource)
    return highest</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.invalid_conf"><code class="name flex">
<span>def <span class="ident">invalid_conf</span></span>(<span>self, config)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def invalid_conf(self, config):
    # TODO This code is duplicated on the structures and database snapshoters
    for key, num in [(&#34;POLLING_FREQUENCY&#34;, config.get_value(&#34;POLLING_FREQUENCY&#34;)), (&#34;REQUEST_TIMEOUT&#34;, config.get_value(&#34;REQUEST_TIMEOUT&#34;))]:
        if num &lt; 5:
            return True, &#34;Configuration item &#39;{0}&#39; with a value of &#39;{1}&#39; is likely invalid&#34;.format(key, num)
    return False, &#34;&#34;</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.lowest_current_to_usage_margin"><code class="name flex">
<span>def <span class="ident">lowest_current_to_usage_margin</span></span>(<span>self, container1, container2, resource)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def lowest_current_to_usage_margin(self, container1, container2, resource):
    # Return the container with the lowest margin between resources used and resources set (closest bottleneck)
    lowest, _ = self.sort_containers_by_usage_margin(container1, container2, resource)
    return lowest</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.persist_new_host_information"><code class="name flex">
<span>def <span class="ident">persist_new_host_information</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def persist_new_host_information(self, ):
    def persist_thread(self, host):
        data = self.host_info_cache[host]
        update_structure(data, self.db_handler, self.debug)

    threads = list()
    for host in self.host_info_cache:
        t = Thread(target=persist_thread, args=(self, host,))
        t.start()
        threads.append(t)

    for t in threads:
        t.join()</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.process_request"><code class="name flex">
<span>def <span class="ident">process_request</span></span>(<span>self, request, real_resources, database_resources)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def process_request(self, request, real_resources, database_resources):
    # Create a &#39;fake&#39; container structure with only the required info
    container = {&#34;host_rescaler_ip&#34;: request[&#34;host_rescaler_ip&#34;],
                 &#34;host_rescaler_port&#34;: request[&#34;host_rescaler_port&#34;],
                 &#34;name&#34;: request[&#34;structure&#34;]}

    # Apply the request and get the new resources to set
    try:
        new_resources = self.apply_request(request, real_resources, database_resources)
        if new_resources:
            log_info(&#34;Request: {0} for container : {1} for new resources : {2}&#34;.format(
                request[&#34;action&#34;], request[&#34;structure&#34;], json.dumps(new_resources)), self.debug)

            # Apply changes through a REST call
            set_container_resources(self.rescaler_http_session, container, new_resources, self.debug)
    except (ValueError) as e:
        log_error(&#34;Error with container {0} in applying the request -&gt; {1}&#34;.format(request[&#34;structure&#34;], str(e)), self.debug)
        return
    except (HTTPError) as e:
        log_error(&#34;Error setting container {0} resources -&gt; {1}&#34;.format(request[&#34;structure&#34;], str(e)), self.debug)
        return
    except (Exception) as e:
        log_error(&#34;Error with container {0} -&gt; {1}&#34;.format(request[&#34;structure&#34;], str(e)), self.debug)
        return</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.process_requests"><code class="name flex">
<span>def <span class="ident">process_requests</span></span>(<span>self, reqs)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def process_requests(self, reqs):
    for request in reqs:
        structure_name = request[&#34;structure&#34;]

        # Retrieve structure info
        try:
            structure = self.db_handler.get_structure(structure_name)
        except (requests.exceptions.HTTPError, ValueError):
            log_error(&#34;Error, couldn&#39;t find structure {0} in database&#34;.format(structure_name), self.debug)
            continue

        # Rescale the structure accordingly, whether it is a container or an application
        if structure_is_container(structure):
            self.rescale_container(request, structure)
        elif structure_is_application(structure):
            self.rescale_application(request, structure)
        else:
            log_error(&#34;Unknown type of structure &#39;{0}&#39;&#34;.format(structure[&#34;subtype&#34;]), self.debug)

        # Remove the request from the database
        self.db_handler.delete_request(request)</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.rescale_application"><code class="name flex">
<span>def <span class="ident">rescale_application</span></span>(<span>self, request, structure)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rescale_application(self, request, structure):

    # Get container names that this app uses
    app_containers_names = structure[&#34;containers&#34;]
    app_containers = list()

    for cont_name in app_containers_names:
        # Get the container
        container = self.db_handler.get_structure(cont_name)
        app_containers.append(container)

        # Retrieve host info and cache it in case other containers or applications need it
        if container[&#34;host&#34;] not in self.host_info_cache:
            self.host_info_cache[container[&#34;host&#34;]] = self.db_handler.get_structure(container[&#34;host&#34;])

    total_amount = request[&#34;amount&#34;]

    requests = list()
    remaining_amount = total_amount
    split_amount = APP_SCALING_SPLIT_AMOUNT * (request[&#34;amount&#34;] / abs(request[&#34;amount&#34;]))  # This sets the sign
    request[&#34;amount&#34;] = split_amount

    # Create smaller requests of &#39;split_amount&#39; size
    while abs(remaining_amount) &gt; 0 and abs(remaining_amount) &gt; abs(split_amount):
        requests.append(dict(request))
        remaining_amount -= split_amount

    # If some remaining amount is left, create the last request
    if abs(remaining_amount) &gt; 0:
        request[&#34;amount&#34;] = remaining_amount
        requests.append(dict(request))

    # Get the request usage for all the containers and cache it
    resource_usage_cache = dict()
    for container in app_containers:
        amount, resource = request[&#34;amount&#34;], request[&#34;resource&#34;]
        metrics_to_retrieve = BDWATCHDOG_CONTAINER_METRICS[resource]
        resource_usage_cache[container[&#34;name&#34;]] = self.bdwatchdog_handler.get_structure_timeseries(
            {&#34;host&#34;: container[&#34;name&#34;]}, 10, 20,
            metrics_to_retrieve, RESCALER_CONTAINER_METRICS)

    success, iterations = True, 0
    generated_requests = dict()

    while success and len(requests) &gt; 0:
        request = requests.pop(0)
        success, container_to_rescale, generated_request = self.single_container_rescale(request, app_containers, resource_usage_cache)
        if success:
            # If rescaling was successful, update the container&#39;s resources as they have been rescaled
            for c in app_containers:
                container_name = c[&#34;name&#34;]
                if container_name == container_to_rescale[&#34;name&#34;]:
                    # Initialize
                    if container_name not in generated_requests:
                        generated_requests[container_name] = list()

                    generated_requests[container_name].append(generated_request)
                    container_to_rescale[&#34;resources&#34;][request[&#34;resource&#34;]][&#34;current&#34;] += request[&#34;amount&#34;]
                    app_containers.remove(c)
                    app_containers.append(container_to_rescale)
                    break
        else:
            break

        iterations += 1

    # Collapse all the requests to generate just 1 per container
    final_requests = list()
    for container in generated_requests:
        # Copy the first request as the base request
        flat_request = dict(generated_requests[container][0])
        flat_request[&#34;amount&#34;] = 0
        for request in generated_requests[container]:
            flat_request[&#34;amount&#34;] += request[&#34;amount&#34;]
        final_requests.append(flat_request)
    self.generate_requests(final_requests, structure[&#34;name&#34;])

    if len(requests) &gt; 0:
        # Couldn&#39;t completely rescale the application as some split of a major rescaling operation could not be completed
        log_warning(&#34;App {0} could not be completely rescaled, only: {1} shares of resource: {2} have been scaled&#34;.format(
            request[&#34;structure&#34;], str(int(iterations * split_amount)), request[&#34;resource&#34;]), self.debug)</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.rescale_container"><code class="name flex">
<span>def <span class="ident">rescale_container</span></span>(<span>self, request, structure)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rescale_container(self, request, structure):
    try:
        # Needed for the resources reported in the database (the &#39;max, min&#39; values)
        database_resources = structure

        # Get the resources the container is using from its host NodeScaler (the &#39;current&#39; value)
        c_name = structure[&#34;name&#34;]
        if c_name not in self.container_info_cache or &#34;resources&#34; not in self.container_info_cache[c_name]:
            log_error(&#34;Couldn&#39;t get container&#39;s {0} resources, can&#39;t rescale&#34;.format(c_name), self.debug)
            return
        real_resources = self.container_info_cache[c_name][&#34;resources&#34;]

        # Process the request
        self.process_request(request, real_resources, database_resources)
    except Exception as e:
        log_error(str(e) + &#34; &#34; + str(traceback.format_exc()), self.debug)</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.scale"><code class="name flex">
<span>def <span class="ident">scale</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scale(self, ):
    logging.basicConfig(filename=SERVICE_NAME + &#39;.log&#39;, level=logging.INFO)

    myConfig = MyConfig(CONFIG_DEFAULT_VALUES)

    # Remove previous requests
    log_info(&#34;Purging any previous requests&#34;, True)
    self.filter_requests(0)
    log_info(&#34;----------------------\n&#34;, True)

    while True:
        # Remote database operation
        service = get_service(self.db_handler, SERVICE_NAME)

        # Heartbeat
        beat(self.db_handler, SERVICE_NAME)

        # CONFIG
        myConfig.set_config(service[&#34;config&#34;])
        polling_frequency = myConfig.get_value(&#34;POLLING_FREQUENCY&#34;)
        request_timeout = myConfig.get_value(&#34;REQUEST_TIMEOUT&#34;)
        self.debug = myConfig.get_value(&#34;self.debug&#34;)
        CHECK_CORE_MAP = myConfig.get_value(&#34;CHECK_CORE_MAP&#34;)
        SERVICE_IS_ACTIVATED = myConfig.get_value(&#34;ACTIVE&#34;)

        log_info(&#34;----------------------&#34;, self.debug)
        log_info(&#34;Starting Epoch&#34;, self.debug)
        t0 = time.time()

        ## CHECK INVALID CONFIG ##
        # TODO This code is duplicated on the structures and database snapshoters
        invalid, message = self.invalid_conf(myConfig)
        if invalid:
            log_error(message, self.debug)
            time.sleep(polling_frequency)
            if polling_frequency &lt; 5:
                log_error(&#34;Polling frequency is too short, replacing with DEFAULT value &#39;{0}&#39;&#34;.format(CONFIG_DEFAULT_VALUES[&#34;POLLING_FREQUENCY&#34;]), self.debug)
                polling_frequency = CONFIG_DEFAULT_VALUES[&#34;POLLING_FREQUENCY&#34;]

            log_info(&#34;----------------------\n&#34;, self.debug)
            time.sleep(polling_frequency)
            continue

        if SERVICE_IS_ACTIVATED:

            # Get the container structures and their resource information as such data is going to be needed
            containers = get_structures(self.db_handler, self.debug, subtype=&#34;container&#34;)
            try:
                self.container_info_cache = get_container_resources_dict()  # Reset the cache
            except (Exception, RuntimeError) as e:
                log_error(&#34;Error getting host document, skipping epoch altogether&#34;, self.debug)
                log_error(str(e), self.debug)
                time.sleep(polling_frequency)
                continue

            # Fill the host information cache
            log_info(&#34;Getting host and container info&#34;, self.debug)
            try:
                self.fill_host_info_cache(containers)
            except (Exception, RuntimeError) as e:
                log_error(&#34;Error getting host document, skipping epoch altogether&#34;, self.debug)
                log_error(str(e), self.debug)
                time.sleep(polling_frequency)
                continue

            # Do the core mapping check-up
            if CHECK_CORE_MAP:
                log_info(&#34;Doing container CPU limits check&#34;, self.debug)
                log_info(&#34;First hosts&#34;, self.debug)
                errors_detected = self.check_host_cpu_limits()
                if errors_detected:
                    log_error(&#34;Errors detected during host CPU limits check&#34;, self.debug)

                log_info(&#34;Second containers&#34;, self.debug)
                errors_detected = self.check_containers_cpu_limits(containers)
                if errors_detected:
                    log_error(&#34;Errors detected during container CPU limits check&#34;, self.debug)

                log_info(&#34;Doing core mapping check&#34;, self.debug)
                errors_detected = self.check_core_mapping(containers)
                if errors_detected:
                    log_error(&#34;Errors detected during container CPU map check&#34;, self.debug)
            else:
                log_warning(&#34;Core map check has been disabled&#34;, self.debug)

            # Get the requests
            new_requests = self.filter_requests(request_timeout)
            container_reqs, app_reqs = self.sort_requests(new_requests)

            # Process first the application requests, as they generate container ones
            if app_reqs:
                log_info(&#34;Processing applications requests&#34;, self.debug)
                self.scale_structures(app_reqs)
            else:
                log_info(&#34;No applications requests&#34;, self.debug)

            # Then process container ones
            if container_reqs:
                log_info(&#34;Processing container requests&#34;, self.debug)
                self.scale_structures(container_reqs)
            else:
                log_info(&#34;No container requests&#34;, self.debug)

            t1 = time.time()
            log_info(&#34;Epoch processed in {0} seconds&#34;.format(str(&#34;%.2f&#34; % (t1 - t0))), self.debug)

        else:
            log_warning(&#34;Scaler service is not activated&#34;, self.debug)

        log_info(&#34;----------------------\n&#34;, self.debug)
        time.sleep(polling_frequency)</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.scale_structures"><code class="name flex">
<span>def <span class="ident">scale_structures</span></span>(<span>self, new_requests)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scale_structures(self, new_requests):
    log_info(&#34;Processing requests&#34;, self.debug)

    t0 = time.time()

    # Split the requests between scale down and scale up
    scale_down, scale_up = self.split_requests(new_requests)

    # Process first the requests that free resources, then the one that use them
    self.process_requests(scale_down)
    self.process_requests(scale_up)

    # Persist the new host information
    self.persist_new_host_information()

    t1 = time.time()
    log_info(&#34;It took {0} seconds to process requests&#34;.format(str(&#34;%.2f&#34; % (t1 - t0))), self.debug)</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.single_container_rescale"><code class="name flex">
<span>def <span class="ident">single_container_rescale</span></span>(<span>self, request, app_containers, resource_usage_cache)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def single_container_rescale(self, request, app_containers, resource_usage_cache):
    amount, resource_label = request[&#34;amount&#34;], request[&#34;resource&#34;]
    scalable_containers = list()
    resource_shares = abs(amount)

    # Look for containers that can be rescaled
    for container in app_containers:
        usages = resource_usage_cache[container[&#34;name&#34;]]
        container[&#34;resources&#34;][resource_label][&#34;usage&#34;] = usages[resource_label]
        current_value = container[&#34;resources&#34;][resource_label][&#34;current&#34;]

        # Rescale down
        if amount &lt; 0:
            # Check that the container has enough free resource shares
            # available to be released and that it would be able
            # to be rescaled without dropping under the minimum value
            if current_value &lt; resource_shares:
                # Container doesn&#39;t have enough resources to free
                # (&#34;Container doesn&#39;t have enough resources to free&#34;, self.debug)
                pass
            elif current_value + amount &lt; container[&#34;resources&#34;][resource_label][&#34;min&#34;]:
                # Container can&#39;t free that amount without dropping under the minimum
                # log_error(&#34;Container {0} can&#39;t free that amount without dropping under the minimum&#34;.format(container[&#34;name&#34;]), self.debug)
                pass
            else:
                scalable_containers.append(container)

        # Rescale up
        else:
            # Check that the container has enough free resource shares available in the host and that it would be able
            # to be rescaled without exceeded the maximum value
            container_host = container[&#34;host&#34;]

            if self.host_info_cache[container_host][&#34;resources&#34;][resource_label][&#34;free&#34;] &lt; resource_shares:
                # Container&#39;s host doesn&#39;t have enough free resources
                # log_error(&#34;Container&#39;s host doesn&#39;t have enough free resources&#34;, self.debug)
                pass
            elif current_value + amount &gt; container[&#34;resources&#34;][resource_label][&#34;max&#34;]:
                # Container can&#39;t get that amount without exceeding the maximum
                # log_error(&#34;Container can&#39;t get that amount without exceeding the maximum&#34;, self.debug)
                pass
            else:
                scalable_containers.append(container)

    # Look for the best fit container for this resource and launch the rescaling request for it
    if scalable_containers:
        best_fit_container = scalable_containers[0]

        for container in scalable_containers[1:]:
            if amount &lt; 0:
                # If scaling down, look for containers with usages far from the limit (underuse)
                best_fit_container = self.highest_current_to_usage_margin(container, best_fit_container, resource_label)
            else:
                # If scaling up, look for containers with usages close to the limit (bottleneck)
                best_fit_container = self.lowest_current_to_usage_margin(container, best_fit_container, resource_label)

        # Generate the new request
        new_request = Guardian.generate_request(best_fit_container, amount, resource_label)

        return True, best_fit_container, new_request
    else:
        return False, {}, {}</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.sort_containers_by_usage_margin"><code class="name flex">
<span>def <span class="ident">sort_containers_by_usage_margin</span></span>(<span>self, container1, container2, resource)</span>
</code></dt>
<dd>
<section class="desc"><h2 id="parameters">Parameters</h2>
<p>container1: dict -&gt; A container structure
container2: dict -&gt; A container structure
resource: str -&gt; the resource to be used for sorting</p>
<h2 id="returns">Returns</h2>
<p>The tuple of the containers with the (lowest,highest) margin between resources used and resources set</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sort_containers_by_usage_margin(self, container1, container2, resource):
    &#34;&#34;&#34;
    Parameters:
        container1: dict -&gt; A container structure
        container2: dict -&gt; A container structure
        resource: str -&gt; the resource to be used for sorting
    Returns:
        The tuple of the containers with the (lowest,highest) margin between resources used and resources set
    &#34;&#34;&#34;
    c1_current_amount = container1[&#34;resources&#34;][resource][&#34;current&#34;]
    c1_usage_amount = container1[&#34;resources&#34;][resource][&#34;usage&#34;]
    c2_current_amount = container2[&#34;resources&#34;][resource][&#34;current&#34;]
    c2_usage_amount = container2[&#34;resources&#34;][resource][&#34;usage&#34;]
    if c1_current_amount - c1_usage_amount &lt; c2_current_amount - c2_usage_amount:
        lowest, highest = container1, container2
    else:
        lowest, highest = container2, container1

    return lowest, highest</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.sort_requests"><code class="name flex">
<span>def <span class="ident">sort_requests</span></span>(<span>self, new_requests)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sort_requests(self, new_requests):
    container_reqs, app_reqs = list(), list()
    for r in new_requests:
        if r[&#34;structure_type&#34;] == &#34;container&#34;:
            container_reqs.append(r)
        elif r[&#34;structure_type&#34;] == &#34;application&#34;:
            app_reqs.append(r)
        else:
            pass
    return container_reqs, app_reqs</code></pre>
</details>
</dd>
<dt id="src.Scaler.Scaler.Scaler.split_requests"><code class="name flex">
<span>def <span class="ident">split_requests</span></span>(<span>self, all_requests)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def split_requests(self, all_requests):
    scale_down, scale_up = list(), list()
    for request in all_requests:
        if &#34;action&#34; not in request or not request[&#34;action&#34;]:
            continue
        elif request[&#34;action&#34;].endswith(&#34;Down&#34;):
            scale_down.append(request)
        elif request[&#34;action&#34;].endswith(&#34;Up&#34;):
            scale_up.append(request)
    return scale_down, scale_up</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<a href="http://bdwatchdog.dec.udc.es/ServerlessContainers/documentation/web/index.html">
<img src="https://s3-eu-west-1.amazonaws.com/jonatan.enes.udc/serverless_containers_website/logo_serverless.png" style="height:100px;"/>
</a>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="src.Scaler" href="index.html">src.Scaler</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="src.Scaler.Scaler.main" href="#src.Scaler.Scaler.main">main</a></code></li>
<li><code><a title="src.Scaler.Scaler.set_container_resources" href="#src.Scaler.Scaler.set_container_resources">set_container_resources</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="src.Scaler.Scaler.Scaler" href="#src.Scaler.Scaler.Scaler">Scaler</a></code></h4>
<ul class="">
<li><code><a title="src.Scaler.Scaler.Scaler.apply_cpu_request" href="#src.Scaler.Scaler.Scaler.apply_cpu_request">apply_cpu_request</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.apply_disk_request" href="#src.Scaler.Scaler.Scaler.apply_disk_request">apply_disk_request</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.apply_mem_request" href="#src.Scaler.Scaler.Scaler.apply_mem_request">apply_mem_request</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.apply_net_request" href="#src.Scaler.Scaler.Scaler.apply_net_request">apply_net_request</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.apply_request" href="#src.Scaler.Scaler.Scaler.apply_request">apply_request</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.check_container_core_mapping" href="#src.Scaler.Scaler.Scaler.check_container_core_mapping">check_container_core_mapping</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.check_container_cpu_mapping" href="#src.Scaler.Scaler.Scaler.check_container_cpu_mapping">check_container_cpu_mapping</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.check_containers_cpu_limits" href="#src.Scaler.Scaler.Scaler.check_containers_cpu_limits">check_containers_cpu_limits</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.check_core_mapping" href="#src.Scaler.Scaler.Scaler.check_core_mapping">check_core_mapping</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.check_host_cpu_limits" href="#src.Scaler.Scaler.Scaler.check_host_cpu_limits">check_host_cpu_limits</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.check_host_has_enough_free_resources" href="#src.Scaler.Scaler.Scaler.check_host_has_enough_free_resources">check_host_has_enough_free_resources</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.check_invalid_resource_value" href="#src.Scaler.Scaler.Scaler.check_invalid_resource_value">check_invalid_resource_value</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.fill_host_info_cache" href="#src.Scaler.Scaler.Scaler.fill_host_info_cache">fill_host_info_cache</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.filter_requests" href="#src.Scaler.Scaler.Scaler.filter_requests">filter_requests</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.fix_container_cpu_mapping" href="#src.Scaler.Scaler.Scaler.fix_container_cpu_mapping">fix_container_cpu_mapping</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.generate_requests" href="#src.Scaler.Scaler.Scaler.generate_requests">generate_requests</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.get_cpu_list" href="#src.Scaler.Scaler.Scaler.get_cpu_list">get_cpu_list</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.get_current_resource_value" href="#src.Scaler.Scaler.Scaler.get_current_resource_value">get_current_resource_value</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.highest_current_to_usage_margin" href="#src.Scaler.Scaler.Scaler.highest_current_to_usage_margin">highest_current_to_usage_margin</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.invalid_conf" href="#src.Scaler.Scaler.Scaler.invalid_conf">invalid_conf</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.lowest_current_to_usage_margin" href="#src.Scaler.Scaler.Scaler.lowest_current_to_usage_margin">lowest_current_to_usage_margin</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.persist_new_host_information" href="#src.Scaler.Scaler.Scaler.persist_new_host_information">persist_new_host_information</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.process_request" href="#src.Scaler.Scaler.Scaler.process_request">process_request</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.process_requests" href="#src.Scaler.Scaler.Scaler.process_requests">process_requests</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.rescale_application" href="#src.Scaler.Scaler.Scaler.rescale_application">rescale_application</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.rescale_container" href="#src.Scaler.Scaler.Scaler.rescale_container">rescale_container</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.scale" href="#src.Scaler.Scaler.Scaler.scale">scale</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.scale_structures" href="#src.Scaler.Scaler.Scaler.scale_structures">scale_structures</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.single_container_rescale" href="#src.Scaler.Scaler.Scaler.single_container_rescale">single_container_rescale</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.sort_containers_by_usage_margin" href="#src.Scaler.Scaler.Scaler.sort_containers_by_usage_margin">sort_containers_by_usage_margin</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.sort_requests" href="#src.Scaler.Scaler.Scaler.sort_requests">sort_requests</a></code></li>
<li><code><a title="src.Scaler.Scaler.Scaler.split_requests" href="#src.Scaler.Scaler.Scaler.split_requests">split_requests</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<!--Grid row-->
<div class="row">
<div class="footer_image">
<a href="http://gac.udc.es/english/">
<img src="https://s3-eu-west-1.amazonaws.com/jonatan.enes.udc/serverless_containers_website/footer/logotipoingles.png"
class="img-fluid" alt="">
<div class="mask rgba-white-light"></div>
</a>
</div>
<div class="footer_image">
<a href="http://www.mineco.gob.es">
<img src="https://s3-eu-west-1.amazonaws.com/jonatan.enes.udc/serverless_containers_website/footer/mineco.jpg"
class="img-fluid" alt="">
<div class="mask rgba-white-light"></div>
</a>
</div>
<div class="footer_image">
<img src="https://s3-eu-west-1.amazonaws.com/jonatan.enes.udc/serverless_containers_website/footer/feder.jpg"
class="img-fluid" alt="">
</div>
<div class="footer_image">
<a href="http://www.udc.es/index.html?language=en">
<img src="https://s3-eu-west-1.amazonaws.com/jonatan.enes.udc/serverless_containers_website/footer/03_Simbolo_logo_cor.png"
class="img-fluid" alt="">
<div class="mask rgba-white-light"></div>
</a>
</div>
</div>
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>